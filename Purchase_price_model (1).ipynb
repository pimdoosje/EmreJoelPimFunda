{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing prepared csv file\n",
    "df_cleaned = pd.read_csv('prepared_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>soortWoning_cleaned</th>\n",
       "      <th>postcode_prepared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>8985600000000000</td>\n",
       "      <td>vrijstaande_woning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>267500.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>9763200000000000</td>\n",
       "      <td>appartement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>349000.0</td>\n",
       "      <td>1973</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>11404800000000000</td>\n",
       "      <td>eengezinswoning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>323</td>\n",
       "      <td>10627200000000000</td>\n",
       "      <td>vrijstaande_woning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>20995200000000000</td>\n",
       "      <td>eengezinswoning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  koopPrijs  bouwjaar  indTuin  aantalKamers  oppervlakte  \\\n",
       "0           0   139000.0      1971        1             3           62   \n",
       "1           2   267500.0      2001        0             3           70   \n",
       "2           3   349000.0      1973        1             5          144   \n",
       "3           4   495000.0      1900        0             8          323   \n",
       "4           5   162500.0      1970        1             4           68   \n",
       "\n",
       "        Time_to_sell soortWoning_cleaned  postcode_prepared  \n",
       "0   8985600000000000  vrijstaande_woning                  0  \n",
       "1   9763200000000000         appartement                  1  \n",
       "2  11404800000000000     eengezinswoning                  2  \n",
       "3  10627200000000000  vrijstaande_woning                  3  \n",
       "4  20995200000000000     eengezinswoning                  4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the header of the cleaned csv header\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               int64\n",
       "koopPrijs              float64\n",
       "bouwjaar                 int64\n",
       "indTuin                  int64\n",
       "aantalKamers             int64\n",
       "oppervlakte              int64\n",
       "Time_to_sell             int64\n",
       "soortWoning_cleaned     object\n",
       "postcode_prepared        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing all data types and making sure that all of them are integers or float except the soortwoning which still has to be dummified\n",
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "koopPrijs              0\n",
       "bouwjaar               0\n",
       "indTuin                0\n",
       "aantalKamers           0\n",
       "oppervlakte            0\n",
       "Time_to_sell           0\n",
       "soortWoning_cleaned    0\n",
       "postcode_prepared      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last transformation to make the data set ready for modelling\n",
    "df= df_cleaned\n",
    "columns = ['Time_to_sell']\n",
    "for col in columns:\n",
    "    df[col] = df[col].astype('int64')\n",
    "\n",
    "df = df_cleaned.rename(columns={'Unnamed: 0': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the splitter to split the data set between training, testing and validation sets\n",
    "class TrainTestSplitter(object):\n",
    "    '''Class to perform the split of the data into train, test, and validation.\n",
    "    '''\n",
    "    def __init__(self, train_frac=0.8, validation_frac=0.2, seed=1234):\n",
    "        self.train_frac = train_frac\n",
    "        self.validation_frac = validation_frac\n",
    "        self.seed = seed\n",
    "\n",
    "    def split_train_test(self, df):\n",
    "        print(\"Generating the train/validation/test splits...\")\n",
    "        self.train_set = df.sample(frac=self.train_frac, random_state=self.seed)\n",
    "        self.test_set = df.loc[lambda x: ~x.id.isin(self.train_set.id)].reset_index(drop=True)\n",
    "        self.validation_set = self.train_set.sample(frac=self.validation_frac).reset_index(drop=True)\n",
    "        self.train_set = self.train_set.loc[lambda x: ~x.id.isin(self.validation_set.id)].reset_index(drop=True)\n",
    "        print(\"calculating the statistics...\")\n",
    "        print(\"split completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the train/validation/test splits...\n",
      "calculating the statistics...\n",
      "split completed\n"
     ]
    }
   ],
   "source": [
    "# create a fitting_splits object that will hold the train, validation, and test data\n",
    "fitting_splits = TrainTestSplitter()\n",
    "fitting_splits.split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131274, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(41023, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32818, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if they're devided correctly\n",
    "fitting_splits.train_set.shape\n",
    "fitting_splits.test_set.shape\n",
    "fitting_splits.validation_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummify the soortWoning column, in the training set: from catagory to integer \n",
    "# this needs to be done, so the outcomes become numbers. Only number can be used in creating the model.\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoder.fit(fitting_splits.train_set[['soortWoning_cleaned']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['appartement', 'benedenwoning', 'bovenwoning', 'eengezinswoning',\n",
       "        'herenhuis', 'other', 'portiekflat', 'vrijstaande_woning'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['soortWoning_cleaned_appartement',\n",
       "       'soortWoning_cleaned_benedenwoning',\n",
       "       'soortWoning_cleaned_bovenwoning',\n",
       "       'soortWoning_cleaned_eengezinswoning',\n",
       "       'soortWoning_cleaned_herenhuis', 'soortWoning_cleaned_other',\n",
       "       'soortWoning_cleaned_portiekflat',\n",
       "       'soortWoning_cleaned_vrijstaande_woning'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>soortWoning_cleaned_bovenwoning</th>\n",
       "      <th>soortWoning_cleaned_eengezinswoning</th>\n",
       "      <th>soortWoning_cleaned_herenhuis</th>\n",
       "      <th>soortWoning_cleaned_other</th>\n",
       "      <th>soortWoning_cleaned_portiekflat</th>\n",
       "      <th>soortWoning_cleaned_vrijstaande_woning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131269</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131272</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131273</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131274 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        soortWoning_cleaned_appartement  soortWoning_cleaned_benedenwoning  \\\n",
       "0                                   0.0                                0.0   \n",
       "1                                   0.0                                0.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   1.0                                0.0   \n",
       "4                                   0.0                                0.0   \n",
       "...                                 ...                                ...   \n",
       "131269                              1.0                                0.0   \n",
       "131270                              0.0                                0.0   \n",
       "131271                              1.0                                0.0   \n",
       "131272                              1.0                                0.0   \n",
       "131273                              1.0                                0.0   \n",
       "\n",
       "        soortWoning_cleaned_bovenwoning  soortWoning_cleaned_eengezinswoning  \\\n",
       "0                                   0.0                                  1.0   \n",
       "1                                   0.0                                  0.0   \n",
       "2                                   0.0                                  1.0   \n",
       "3                                   0.0                                  0.0   \n",
       "4                                   0.0                                  0.0   \n",
       "...                                 ...                                  ...   \n",
       "131269                              0.0                                  0.0   \n",
       "131270                              0.0                                  1.0   \n",
       "131271                              0.0                                  0.0   \n",
       "131272                              0.0                                  0.0   \n",
       "131273                              0.0                                  0.0   \n",
       "\n",
       "        soortWoning_cleaned_herenhuis  soortWoning_cleaned_other  \\\n",
       "0                                 0.0                        0.0   \n",
       "1                                 0.0                        0.0   \n",
       "2                                 0.0                        0.0   \n",
       "3                                 0.0                        0.0   \n",
       "4                                 0.0                        0.0   \n",
       "...                               ...                        ...   \n",
       "131269                            0.0                        0.0   \n",
       "131270                            0.0                        0.0   \n",
       "131271                            0.0                        0.0   \n",
       "131272                            0.0                        0.0   \n",
       "131273                            0.0                        0.0   \n",
       "\n",
       "        soortWoning_cleaned_portiekflat  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "...                                 ...   \n",
       "131269                              0.0   \n",
       "131270                              0.0   \n",
       "131271                              0.0   \n",
       "131272                              0.0   \n",
       "131273                              0.0   \n",
       "\n",
       "        soortWoning_cleaned_vrijstaande_woning  \n",
       "0                                          0.0  \n",
       "1                                          1.0  \n",
       "2                                          0.0  \n",
       "3                                          0.0  \n",
       "4                                          1.0  \n",
       "...                                        ...  \n",
       "131269                                     0.0  \n",
       "131270                                     0.0  \n",
       "131271                                     0.0  \n",
       "131272                                     0.0  \n",
       "131273                                     0.0  \n",
       "\n",
       "[131274 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the encoder\n",
    "one_hot_encoder.categories_ # after we fit the encoder, the instance learns which values are present in each data column.\n",
    "encoded_names = one_hot_encoder.get_feature_names_out() # with this method we can retrieve the names of the new dummy columns that have been computed\n",
    "encoded_names\n",
    "\n",
    "encoded_categories = one_hot_encoder.transform(fitting_splits.train_set[['soortWoning_cleaned']]).toarray() # at this point, we can use the fitted encoder to transform any array with a sex and marriage column; not just the training set, but also the validation or test set. The encoder will take that array of shape (M,2) and transform it to an array of shape (M, N), where N is the total number of distinct possible values for the encoded features. The values of the new array will be either 0 or 1, encoding whether that value of the feature applies to the row.\n",
    "df_encoded = pd.DataFrame(encoded_categories)\n",
    "df_encoded.columns = encoded_names\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>postcode_prepared</th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>soortWoning_cleaned_bovenwoning</th>\n",
       "      <th>soortWoning_cleaned_eengezinswoning</th>\n",
       "      <th>soortWoning_cleaned_herenhuis</th>\n",
       "      <th>soortWoning_cleaned_other</th>\n",
       "      <th>soortWoning_cleaned_portiekflat</th>\n",
       "      <th>soortWoning_cleaned_vrijstaande_woning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9239</td>\n",
       "      <td>249500.0</td>\n",
       "      <td>1939</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>1296000000000000</td>\n",
       "      <td>8894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30049</td>\n",
       "      <td>698000.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>178</td>\n",
       "      <td>23328000000000000</td>\n",
       "      <td>29092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163972</td>\n",
       "      <td>289500.0</td>\n",
       "      <td>1956</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>2419200000000000</td>\n",
       "      <td>160641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181829</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>2332800000000000</td>\n",
       "      <td>178244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32736</td>\n",
       "      <td>298000.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>13392000000000000</td>\n",
       "      <td>31722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131269</th>\n",
       "      <td>171619</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>1296000000000000</td>\n",
       "      <td>168188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131270</th>\n",
       "      <td>150845</td>\n",
       "      <td>209000.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>1382400000000000</td>\n",
       "      <td>147665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131271</th>\n",
       "      <td>6265</td>\n",
       "      <td>189000.0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>8467200000000000</td>\n",
       "      <td>6020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131272</th>\n",
       "      <td>27376</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>1982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1123200000000000</td>\n",
       "      <td>26489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131273</th>\n",
       "      <td>13898</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>1209600000000000</td>\n",
       "      <td>13350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131274 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  koopPrijs  bouwjaar  indTuin  aantalKamers  oppervlakte  \\\n",
       "0         9239   249500.0      1939        1             6          105   \n",
       "1        30049   698000.0      1937        1             6          178   \n",
       "2       163972   289500.0      1956        1             4          123   \n",
       "3       181829   189000.0      1966        0             3           62   \n",
       "4        32736   298000.0      1996        1             5          116   \n",
       "...        ...        ...       ...      ...           ...          ...   \n",
       "131269  171619   250000.0      2005        1             3           73   \n",
       "131270  150845   209000.0      1981        1             6          120   \n",
       "131271    6265   189000.0      1995        0             4           72   \n",
       "131272   27376   195000.0      1982        0             1           29   \n",
       "131273   13898   150000.0      2008        0             2           55   \n",
       "\n",
       "             Time_to_sell  postcode_prepared  soortWoning_cleaned_appartement  \\\n",
       "0        1296000000000000               8894                              0.0   \n",
       "1       23328000000000000              29092                              0.0   \n",
       "2        2419200000000000             160641                              0.0   \n",
       "3        2332800000000000             178244                              1.0   \n",
       "4       13392000000000000              31722                              0.0   \n",
       "...                   ...                ...                              ...   \n",
       "131269   1296000000000000             168188                              1.0   \n",
       "131270   1382400000000000             147665                              0.0   \n",
       "131271   8467200000000000               6020                              1.0   \n",
       "131272   1123200000000000              26489                              1.0   \n",
       "131273   1209600000000000              13350                              1.0   \n",
       "\n",
       "        soortWoning_cleaned_benedenwoning  soortWoning_cleaned_bovenwoning  \\\n",
       "0                                     0.0                              0.0   \n",
       "1                                     0.0                              0.0   \n",
       "2                                     0.0                              0.0   \n",
       "3                                     0.0                              0.0   \n",
       "4                                     0.0                              0.0   \n",
       "...                                   ...                              ...   \n",
       "131269                                0.0                              0.0   \n",
       "131270                                0.0                              0.0   \n",
       "131271                                0.0                              0.0   \n",
       "131272                                0.0                              0.0   \n",
       "131273                                0.0                              0.0   \n",
       "\n",
       "        soortWoning_cleaned_eengezinswoning  soortWoning_cleaned_herenhuis  \\\n",
       "0                                       1.0                            0.0   \n",
       "1                                       0.0                            0.0   \n",
       "2                                       1.0                            0.0   \n",
       "3                                       0.0                            0.0   \n",
       "4                                       0.0                            0.0   \n",
       "...                                     ...                            ...   \n",
       "131269                                  0.0                            0.0   \n",
       "131270                                  1.0                            0.0   \n",
       "131271                                  0.0                            0.0   \n",
       "131272                                  0.0                            0.0   \n",
       "131273                                  0.0                            0.0   \n",
       "\n",
       "        soortWoning_cleaned_other  soortWoning_cleaned_portiekflat  \\\n",
       "0                             0.0                              0.0   \n",
       "1                             0.0                              0.0   \n",
       "2                             0.0                              0.0   \n",
       "3                             0.0                              0.0   \n",
       "4                             0.0                              0.0   \n",
       "...                           ...                              ...   \n",
       "131269                        0.0                              0.0   \n",
       "131270                        0.0                              0.0   \n",
       "131271                        0.0                              0.0   \n",
       "131272                        0.0                              0.0   \n",
       "131273                        0.0                              0.0   \n",
       "\n",
       "        soortWoning_cleaned_vrijstaande_woning  \n",
       "0                                          0.0  \n",
       "1                                          1.0  \n",
       "2                                          0.0  \n",
       "3                                          0.0  \n",
       "4                                          1.0  \n",
       "...                                        ...  \n",
       "131269                                     0.0  \n",
       "131270                                     0.0  \n",
       "131271                                     0.0  \n",
       "131272                                     0.0  \n",
       "131273                                     0.0  \n",
       "\n",
       "[131274 rows x 16 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the non dummified woning column and the adding the dummified array to our training dataset\n",
    "train_set = fitting_splits.train_set.drop(['soortWoning_cleaned'], axis=1)\n",
    "train_set = pd.concat([train_set, df_encoded], axis=1)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the scaler\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparer(object):\n",
    "    def __init__(self, one_hot_encoder, standard_scaler):\n",
    "        self.one_hot_encoder = one_hot_encoder\n",
    "        self.standard_scaler = standard_scaler\n",
    "\n",
    "    def dummify(self, df):\n",
    "        vars_to_encode = ['soortWoning_cleaned']\n",
    "        df_to_encode = df[vars_to_encode]\n",
    "        df_encoded = self.one_hot_encoder.transform(df_to_encode).toarray()\n",
    "        df_encoded = pd.DataFrame(df_encoded)\n",
    "        df_encoded.columns = self.one_hot_encoder.get_feature_names_out()\n",
    "        # add the encoded columns and drop the original columns\n",
    "        df = df.drop(vars_to_encode,axis=1)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        return df\n",
    "\n",
    "    def scale(self, df):\n",
    "        cols = df.columns\n",
    "        df = self.standard_scaler.transform(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = cols\n",
    "        return df\n",
    "\n",
    "    def prepare_data(self, df):\n",
    "        df = df.reset_index(drop=True)\n",
    "        # first dummify the data\n",
    "        df = self.dummify(df)\n",
    "        # then scale it\n",
    "        df = self.scale(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>postcode_prepared</th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>soortWoning_cleaned_bovenwoning</th>\n",
       "      <th>soortWoning_cleaned_eengezinswoning</th>\n",
       "      <th>soortWoning_cleaned_herenhuis</th>\n",
       "      <th>soortWoning_cleaned_other</th>\n",
       "      <th>soortWoning_cleaned_portiekflat</th>\n",
       "      <th>soortWoning_cleaned_vrijstaande_woning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.590274</td>\n",
       "      <td>-0.356729</td>\n",
       "      <td>-0.905912</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>0.859377</td>\n",
       "      <td>-0.303818</td>\n",
       "      <td>-0.673633</td>\n",
       "      <td>-1.586286</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.249147</td>\n",
       "      <td>1.946539</td>\n",
       "      <td>-0.957764</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>0.859377</td>\n",
       "      <td>1.191625</td>\n",
       "      <td>2.917608</td>\n",
       "      <td>-1.249193</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-1.050499</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>2.265962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946180</td>\n",
       "      <td>-0.151310</td>\n",
       "      <td>-0.465164</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>-0.421143</td>\n",
       "      <td>0.064922</td>\n",
       "      <td>-0.490550</td>\n",
       "      <td>0.946286</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.238901</td>\n",
       "      <td>-0.667427</td>\n",
       "      <td>-0.205901</td>\n",
       "      <td>-1.571977</td>\n",
       "      <td>-1.061403</td>\n",
       "      <td>-1.184695</td>\n",
       "      <td>-0.504634</td>\n",
       "      <td>1.240070</td>\n",
       "      <td>1.995905</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-1.050499</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.205100</td>\n",
       "      <td>-0.107658</td>\n",
       "      <td>0.571889</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>0.219117</td>\n",
       "      <td>-0.078477</td>\n",
       "      <td>1.298029</td>\n",
       "      <td>-1.205299</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-1.050499</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>2.265962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  koopPrijs  bouwjaar   indTuin  aantalKamers  oppervlakte  \\\n",
       "0 -1.590274  -0.356729 -0.905912  0.636142      0.859377    -0.303818   \n",
       "1 -1.249147   1.946539 -0.957764  0.636142      0.859377     1.191625   \n",
       "2  0.946180  -0.151310 -0.465164  0.636142     -0.421143     0.064922   \n",
       "3  1.238901  -0.667427 -0.205901 -1.571977     -1.061403    -1.184695   \n",
       "4 -1.205100  -0.107658  0.571889  0.636142      0.219117    -0.078477   \n",
       "\n",
       "   Time_to_sell  postcode_prepared  soortWoning_cleaned_appartement  \\\n",
       "0     -0.673633          -1.586286                        -0.501026   \n",
       "1      2.917608          -1.249193                        -0.501026   \n",
       "2     -0.490550           0.946286                        -0.501026   \n",
       "3     -0.504634           1.240070                         1.995905   \n",
       "4      1.298029          -1.205299                        -0.501026   \n",
       "\n",
       "   soortWoning_cleaned_benedenwoning  soortWoning_cleaned_bovenwoning  \\\n",
       "0                          -0.080729                        -0.127226   \n",
       "1                          -0.080729                        -0.127226   \n",
       "2                          -0.080729                        -0.127226   \n",
       "3                          -0.080729                        -0.127226   \n",
       "4                          -0.080729                        -0.127226   \n",
       "\n",
       "   soortWoning_cleaned_eengezinswoning  soortWoning_cleaned_herenhuis  \\\n",
       "0                             0.951929                      -0.181376   \n",
       "1                            -1.050499                      -0.181376   \n",
       "2                             0.951929                      -0.181376   \n",
       "3                            -1.050499                      -0.181376   \n",
       "4                            -1.050499                      -0.181376   \n",
       "\n",
       "   soortWoning_cleaned_other  soortWoning_cleaned_portiekflat  \\\n",
       "0                  -0.191888                        -0.149823   \n",
       "1                  -0.191888                        -0.149823   \n",
       "2                  -0.191888                        -0.149823   \n",
       "3                  -0.191888                        -0.149823   \n",
       "4                  -0.191888                        -0.149823   \n",
       "\n",
       "   soortWoning_cleaned_vrijstaande_woning  \n",
       "0                               -0.441314  \n",
       "1                                2.265962  \n",
       "2                               -0.441314  \n",
       "3                               -0.441314  \n",
       "4                                2.265962  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>postcode_prepared</th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>soortWoning_cleaned_bovenwoning</th>\n",
       "      <th>soortWoning_cleaned_eengezinswoning</th>\n",
       "      <th>soortWoning_cleaned_herenhuis</th>\n",
       "      <th>soortWoning_cleaned_other</th>\n",
       "      <th>soortWoning_cleaned_portiekflat</th>\n",
       "      <th>soortWoning_cleaned_vrijstaande_woning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359632</td>\n",
       "      <td>-0.107658</td>\n",
       "      <td>1.168194</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>0.859377</td>\n",
       "      <td>0.577059</td>\n",
       "      <td>1.002279</td>\n",
       "      <td>-1.358475</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.051633</td>\n",
       "      <td>-0.921633</td>\n",
       "      <td>-0.361459</td>\n",
       "      <td>-1.571977</td>\n",
       "      <td>-1.701663</td>\n",
       "      <td>-1.594405</td>\n",
       "      <td>-0.701800</td>\n",
       "      <td>1.052214</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-1.050499</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>6.674550</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110313</td>\n",
       "      <td>1.129996</td>\n",
       "      <td>0.623741</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>1.499637</td>\n",
       "      <td>1.683277</td>\n",
       "      <td>-0.082135</td>\n",
       "      <td>0.109561</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-1.050499</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>2.265962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.497870</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>-0.257754</td>\n",
       "      <td>-1.571977</td>\n",
       "      <td>-1.701663</td>\n",
       "      <td>-1.451006</td>\n",
       "      <td>1.368445</td>\n",
       "      <td>-1.496029</td>\n",
       "      <td>1.995905</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>-1.050499</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.140694</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.364478</td>\n",
       "      <td>0.636142</td>\n",
       "      <td>0.219117</td>\n",
       "      <td>-0.324303</td>\n",
       "      <td>-0.603217</td>\n",
       "      <td>-1.141646</td>\n",
       "      <td>-0.501026</td>\n",
       "      <td>-0.080729</td>\n",
       "      <td>-0.127226</td>\n",
       "      <td>0.951929</td>\n",
       "      <td>-0.181376</td>\n",
       "      <td>-0.191888</td>\n",
       "      <td>-0.149823</td>\n",
       "      <td>-0.441314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  koopPrijs  bouwjaar   indTuin  aantalKamers  oppervlakte  \\\n",
       "0 -1.359632  -0.107658  1.168194  0.636142      0.859377     0.577059   \n",
       "1  1.051633  -0.921633 -0.361459 -1.571977     -1.701663    -1.594405   \n",
       "2  0.110313   1.129996  0.623741  0.636142      1.499637     1.683277   \n",
       "3 -1.497870   0.621582 -0.257754 -1.571977     -1.701663    -1.451006   \n",
       "4 -1.140694   0.031000  0.364478  0.636142      0.219117    -0.324303   \n",
       "\n",
       "   Time_to_sell  postcode_prepared  soortWoning_cleaned_appartement  \\\n",
       "0      1.002279          -1.358475                        -0.501026   \n",
       "1     -0.701800           1.052214                        -0.501026   \n",
       "2     -0.082135           0.109561                        -0.501026   \n",
       "3      1.368445          -1.496029                         1.995905   \n",
       "4     -0.603217          -1.141646                        -0.501026   \n",
       "\n",
       "   soortWoning_cleaned_benedenwoning  soortWoning_cleaned_bovenwoning  \\\n",
       "0                          -0.080729                        -0.127226   \n",
       "1                          -0.080729                        -0.127226   \n",
       "2                          -0.080729                        -0.127226   \n",
       "3                          -0.080729                        -0.127226   \n",
       "4                          -0.080729                        -0.127226   \n",
       "\n",
       "   soortWoning_cleaned_eengezinswoning  soortWoning_cleaned_herenhuis  \\\n",
       "0                             0.951929                      -0.181376   \n",
       "1                            -1.050499                      -0.181376   \n",
       "2                            -1.050499                      -0.181376   \n",
       "3                            -1.050499                      -0.181376   \n",
       "4                             0.951929                      -0.181376   \n",
       "\n",
       "   soortWoning_cleaned_other  soortWoning_cleaned_portiekflat  \\\n",
       "0                  -0.191888                        -0.149823   \n",
       "1                  -0.191888                         6.674550   \n",
       "2                  -0.191888                        -0.149823   \n",
       "3                  -0.191888                        -0.149823   \n",
       "4                  -0.191888                        -0.149823   \n",
       "\n",
       "   soortWoning_cleaned_vrijstaande_woning  \n",
       "0                               -0.441314  \n",
       "1                               -0.441314  \n",
       "2                                2.265962  \n",
       "3                               -0.441314  \n",
       "4                               -0.441314  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying one hot encoder and standard scaler\n",
    "data_preparer = DataPreparer(one_hot_encoder, standard_scaler)\n",
    "data_preparer.prepare_data(fitting_splits.train_set).head()\n",
    "data_preparer.prepare_data(fitting_splits.validation_set).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training variables to measure the buying price\n",
    "train_set_transformed = data_preparer.prepare_data(fitting_splits.train_set)\n",
    "X_train = train_set_transformed.drop(['koopPrijs', 'id'], axis=1) # need to drop the target! otherwise data leakage\n",
    "y_train = fitting_splits.train_set['koopPrijs'] # take it from the original untransformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use the fitted random tree model to predict on the test dataset\n",
    "X_test = data_preparer.prepare_data(fitting_splits.test_set).drop(['koopPrijs', 'id'], axis=1)\n",
    "y_test = fitting_splits.test_set['koopPrijs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 76141.36224410696\n",
      "Mean Squared Error: 17676097771.085148\n",
      "Root Mean Squared Error: 132951.48653206232\n"
     ]
    }
   ],
   "source": [
    "# testing model and printing the accuracy measured by the MSE\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'squared_error',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# overview off all hyperparameters\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [20, 40, 60, 80], 'n_estimators': [100, 200, 300, 400]}\n"
     ]
    }
   ],
   "source": [
    "# creating a grid from the hypertuning parameters\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)]\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 80, num = 4)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin hypertuning\n",
      "fitting model for n_estimators: 100 and max_depth: 20\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 100 and max_depth: 40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16556/3843594382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# A new model will be fitted for each loop cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"fitting model for n_estimators: {N} and max_depth: {Depth}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mfitted_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_svm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"fitting complete.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# store the fitted model in the fitted_model list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16556/3843594382.py\u001b[0m in \u001b[0;36mfit_svm_model\u001b[1;34m(X_train, y_train, n_estimators, max_depth)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msimple_RFR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# fit the model instance on X_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msimple_RFR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msimple_RFR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\AI_assignment\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "\n",
    "def fit_svm_model(X_train, y_train, n_estimators, max_depth):\n",
    "    # create the model instance with the required parameters\n",
    "    simple_RFR = RandomForestRegressor(random_state=1234)\n",
    "    # fit the model instance on X_train\n",
    "    simple_RFR.fit(X=X_train, y=y_train)\n",
    "    return simple_RFR\n",
    "\n",
    " # will hold the models fitted on train, for each hyperparameter combination\n",
    "fitted_models = []\n",
    "\n",
    "# train a model for each hyperparameter combo\n",
    "print(\"begin hypertuning\")\n",
    "for N in n_estimators:\n",
    "    for Depth in max_depth:\n",
    "        # fit a model with the given hyperparameter values.\n",
    "        # A new model will be fitted for each loop cycle\n",
    "        print(f\"fitting model for n_estimators: {N} and max_depth: {Depth}\")\n",
    "        fitted_model = fit_svm_model(X_train, y_train, N, Depth)\n",
    "        print(f\"fitting complete.\")\n",
    "        # store the fitted model in the fitted_model list\n",
    "        fitted_models.append(fitted_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressor(random_state=1234)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the first four models\n",
    "fitted_models[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put train & validation sets together\n",
    "X_validation = data_preparer.prepare_data(fitting_splits.validation_set).drop(['koopPrijs', 'id'], axis=1)\n",
    "y_validation = fitting_splits.validation_set['koopPrijs']\n",
    "X_train_validation = pd.concat([X_train, X_validation])\n",
    "y_train_validation = pd.concat([y_train, fitting_splits.validation_set['koopPrijs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating MSE for the model\n",
    "def calculate_MSE(X, y, model):\n",
    "    y_hat = model.predict(X)\n",
    "    return metrics.mean_squared_error(y, y_hat)\n",
    "MSE = [calculate_MSE(X_validation, y_validation, m) for m in fitted_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20329362422.243908]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the first 20 MSE scores\n",
    "MSE[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best MSE from the hypertuning\n",
    "max_MSE = max(MSE)\n",
    "best_model_index = MSE.index(max_MSE)\n",
    "best_model = fitted_models[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of n estimators found is 100\n",
      "The best value of max depth is None\n"
     ]
    }
   ],
   "source": [
    "# printing best parameters\n",
    "print(f\"The best value of n estimators found is {best_model.n_estimators}\")\n",
    "print(f\"The best value of max depth is {best_model.max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1234)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting model with best parameters\n",
    "selected_model = RandomForestRegressor(n_estimators = best_model.n_estimators, max_depth = best_model.max_depth, random_state=1234)\n",
    "selected_model.fit(X_train_validation, y_train_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17597025633.36699"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now predict on test with the fitted model to get the final performance measure\n",
    "X_test = data_preparer.prepare_data(fitting_splits.test_set).drop(['koopPrijs', 'id'],axis=1)\n",
    "y_test = fitting_splits.test_set['koopPrijs']\n",
    "calculate_MSE(X_test, y_test, selected_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.7.0\n",
      "keras: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of neurons for the input layer must be: 14\n"
     ]
    }
   ],
   "source": [
    "# printing best amount of neurons per layer\n",
    "print(f\"The number of neurons for the input layer must be: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network model class instance\n",
    "simple_nn = Sequential()\n",
    "# we set the number of neurons to be equal to the (# of nodes in the input layer + # neurons in the output layer)/2,\n",
    "simple_nn.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "# add the output layer with sigmoid function (the sigmoid function is exactly the same as that used in the formulation of logisitc regression\n",
    "simple_nn.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                150       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(simple_nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting MSE as loss function for the regression problem\n",
    "simple_nn.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131274, 14)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(131274,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32818, 14)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32818,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shapes of arrays \n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_validation.shape\n",
    "y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 139653709824.0000\n",
      "Epoch 2/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 139649187840.0000\n",
      "Epoch 3/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 139638833152.0000\n",
      "Epoch 4/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139623383040.0000\n",
      "Epoch 5/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139602345984.0000\n",
      "Epoch 6/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139575853056.0000: 0s - loss: 1381880\n",
      "Epoch 7/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139544772608.0000\n",
      "Epoch 8/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 139509694464.0000\n",
      "Epoch 9/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139470913536.0000\n",
      "Epoch 10/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139428577280.0000\n",
      "Epoch 11/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 139382931456.0000\n",
      "Epoch 12/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 139333910528.0000\n",
      "Epoch 13/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 139281891328.0000\n",
      "Epoch 14/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 139226759168.0000\n",
      "Epoch 15/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139168530432.0000: 0s - loss: 13764578508\n",
      "Epoch 16/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139107467264.0000: 0s - loss: 1392161\n",
      "Epoch 17/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 139043569664.0000\n",
      "Epoch 18/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 138976968704.0000\n",
      "Epoch 19/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 138907566080.0000\n",
      "Epoch 20/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138835443712.0000\n",
      "Epoch 21/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 138760601600.0000\n",
      "Epoch 22/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138683072512.0000\n",
      "Epoch 23/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 138602905600.0000\n",
      "Epoch 24/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138520084480.0000\n",
      "Epoch 25/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138434805760.0000\n",
      "Epoch 26/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138346823680.0000\n",
      "Epoch 27/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138256285696.0000\n",
      "Epoch 28/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 138163273728.0000\n",
      "Epoch 29/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 138067558400.0000\n",
      "Epoch 30/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137969434624.0000\n",
      "Epoch 31/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137868886016.0000\n",
      "Epoch 32/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137765699584.0000: 0s - loss: 13838806220\n",
      "Epoch 33/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137659990016.0000\n",
      "Epoch 34/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137551872000.0000\n",
      "Epoch 35/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137441263616.0000\n",
      "Epoch 36/150\n",
      "263/263 [==============================] - ETA: 0s - loss: 136957247488.00 - 0s 2ms/step - loss: 137328123904.0000\n",
      "Epoch 37/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137212551168.0000\n",
      "Epoch 38/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 137094545408.0000\n",
      "Epoch 39/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 136974172160.0000\n",
      "Epoch 40/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 136851374080.0000\n",
      "Epoch 41/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 136726118400.0000\n",
      "Epoch 42/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 136598323200.0000\n",
      "Epoch 43/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 136468176896.0000\n",
      "Epoch 44/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 136335572992.0000\n",
      "Epoch 45/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 136200560640.0000\n",
      "Epoch 46/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 136063164416.0000\n",
      "Epoch 47/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 135923490816.0000\n",
      "Epoch 48/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 135781392384.0000\n",
      "Epoch 49/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 135636926464.0000\n",
      "Epoch 50/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 135490068480.0000\n",
      "Epoch 51/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 135340859392.0000\n",
      "Epoch 52/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 135189176320.0000\n",
      "Epoch 53/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 135035142144.0000\n",
      "Epoch 54/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 134878715904.0000\n",
      "Epoch 55/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 134719922176.0000\n",
      "Epoch 56/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 134558793728.0000\n",
      "Epoch 57/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 134395527168.0000\n",
      "Epoch 58/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 134229909504.0000\n",
      "Epoch 59/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 134061998080.0000\n",
      "Epoch 60/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 133891645440.0000\n",
      "Epoch 61/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 133719064576.0000\n",
      "Epoch 62/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 133544321024.0000\n",
      "Epoch 63/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 133367193600.0000\n",
      "Epoch 64/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 133187796992.0000\n",
      "Epoch 65/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 133006327808.0000\n",
      "Epoch 66/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 132822581248.0000\n",
      "Epoch 67/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 132636729344.0000\n",
      "Epoch 68/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 132448444416.0000\n",
      "Epoch 69/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 132258078720.0000\n",
      "Epoch 70/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 132065386496.0000\n",
      "Epoch 71/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 131870679040.0000\n",
      "Epoch 72/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 131673776128.0000\n",
      "Epoch 73/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 131474849792.0000\n",
      "Epoch 74/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 131273760768.0000\n",
      "Epoch 75/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 131070451712.0000\n",
      "Epoch 76/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 130865020928.0000\n",
      "Epoch 77/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 130657353728.0000\n",
      "Epoch 78/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 130447622144.0000\n",
      "Epoch 79/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 130235826176.0000\n",
      "Epoch 80/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 130021859328.0000\n",
      "Epoch 81/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 129805885440.0000\n",
      "Epoch 82/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 129587855360.0000\n",
      "Epoch 83/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 129367695360.0000\n",
      "Epoch 84/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 129145536512.0000\n",
      "Epoch 85/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 128921698304.0000\n",
      "Epoch 86/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 128695648256.0000\n",
      "Epoch 87/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 128467607552.0000\n",
      "Epoch 88/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 128237617152.0000\n",
      "Epoch 89/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 128005554176.0000\n",
      "Epoch 90/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 127771516928.0000\n",
      "Epoch 91/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 127535431680.0000\n",
      "Epoch 92/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 127297421312.0000\n",
      "Epoch 93/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 127057494016.0000\n",
      "Epoch 94/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 126815641600.0000\n",
      "Epoch 95/150\n",
      "263/263 [==============================] - 1s 3ms/step - loss: 126571700224.0000: 0s - loss: 12672\n",
      "Epoch 96/150\n",
      "263/263 [==============================] - 1s 3ms/step - loss: 126325972992.0000\n",
      "Epoch 97/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 126078443520.0000\n",
      "Epoch 98/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 125828800512.0000: 0s - los\n",
      "Epoch 99/150\n",
      "263/263 [==============================] - 1s 3ms/step - loss: 125577207808.0000\n",
      "Epoch 100/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 125323853824.0000: 0s - loss: 1\n",
      "Epoch 101/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 125068697600.0000\n",
      "Epoch 102/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 124811780096.0000\n",
      "Epoch 103/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 124552945664.0000\n",
      "Epoch 104/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 124292325376.0000\n",
      "Epoch 105/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 124029870080.0000\n",
      "Epoch 106/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 123765596160.0000\n",
      "Epoch 107/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 123499470848.0000\n",
      "Epoch 108/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 123231494144.0000\n",
      "Epoch 109/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 122961813504.0000\n",
      "Epoch 110/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 122690494464.0000\n",
      "Epoch 111/150\n",
      "263/263 [==============================] - 1s 3ms/step - loss: 122417348608.0000\n",
      "Epoch 112/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 122142457856.0000\n",
      "Epoch 113/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 121866027008.0000\n",
      "Epoch 114/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 121587769344.0000\n",
      "Epoch 115/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 121307832320.0000\n",
      "Epoch 116/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 121026248704.0000\n",
      "Epoch 117/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 120742838272.0000\n",
      "Epoch 118/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 120457961472.0000\n",
      "Epoch 119/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 120171298816.0000\n",
      "Epoch 120/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 119883202560.0000\n",
      "Epoch 121/150\n",
      "263/263 [==============================] - ETA: 0s - loss: 119250952192.00 - 0s 2ms/step - loss: 119593459712.0000\n",
      "Epoch 122/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 119302078464.0000\n",
      "Epoch 123/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 119009067008.0000\n",
      "Epoch 124/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 118714540032.0000\n",
      "Epoch 125/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 118418464768.0000\n",
      "Epoch 126/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 118120988672.0000\n",
      "Epoch 127/150\n",
      "263/263 [==============================] - ETA: 0s - loss: 117488713728.00 - 0s 1ms/step - loss: 117822038016.0000\n",
      "Epoch 128/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 117521498112.0000\n",
      "Epoch 129/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 117219426304.0000\n",
      "Epoch 130/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 116916142080.0000\n",
      "Epoch 131/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 116611366912.0000\n",
      "Epoch 132/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 116304822272.0000\n",
      "Epoch 133/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 115996966912.0000\n",
      "Epoch 134/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 115687620608.0000\n",
      "Epoch 135/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 115376676864.0000: 0s - loss:\n",
      "Epoch 136/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 115064406016.0000\n",
      "Epoch 137/150\n",
      "263/263 [==============================] - 0s 1ms/step - loss: 114750390272.0000\n",
      "Epoch 138/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 114435194880.0000\n",
      "Epoch 139/150\n",
      "263/263 [==============================] - 1s 3ms/step - loss: 114118803456.0000\n",
      "Epoch 140/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 113801207808.0000\n",
      "Epoch 141/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 113482416128.0000\n",
      "Epoch 142/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 113162215424.0000\n",
      "Epoch 143/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 112840630272.0000\n",
      "Epoch 144/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 112517505024.0000\n",
      "Epoch 145/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 112193355776.0000\n",
      "Epoch 146/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 111868084224.0000\n",
      "Epoch 147/150\n",
      "263/263 [==============================] - 1s 2ms/step - loss: 111541403648.0000\n",
      "Epoch 148/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 111213518848.0000\n",
      "Epoch 149/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 110884306944.0000\n",
      "Epoch 150/150\n",
      "263/263 [==============================] - 0s 2ms/step - loss: 110553792512.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f2fb27af0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the model\n",
    "simple_nn.fit(X_train, y_train, epochs=150, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29f381efdf0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see what information has been logged during the training process\n",
    "simple_nn.history.history.keys()\n",
    "\n",
    "# plot the training loss over epochs\n",
    "loss_df = pd.DataFrame(simple_nn.history.history['loss'])\n",
    "loss_df.columns = ['loss']\n",
    "loss_df = loss_df.assign(epoch = np.arange(1, 151))\n",
    "\n",
    "y = loss_df['loss']\n",
    "x = loss_df['epoch']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "#plt.plot(x,y)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6564/6564 [==============================] - 14s 2ms/step - loss: 106782302208.0000 - val_loss: 109168287744.0000\n",
      "Epoch 2/5\n",
      "6564/6564 [==============================] - 12s 2ms/step - loss: 99527155712.0000 - val_loss: 101531213824.0000\n",
      "Epoch 3/5\n",
      "6564/6564 [==============================] - 14s 2ms/step - loss: 92028665856.0000 - val_loss: 93765468160.0000\n",
      "Epoch 4/5\n",
      "6564/6564 [==============================] - 15s 2ms/step - loss: 84321951744.0000 - val_loss: 85876097024.0000\n",
      "Epoch 5/5\n",
      "6564/6564 [==============================] - 14s 2ms/step - loss: 76702515200.0000 - val_loss: 78154055680.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f4d0ef160>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the model\n",
    "simple_nn.fit(X_train, y_train, epochs=5, batch_size = 20, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29f50d96160>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29f50d96520>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'model loss')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29f50d96760>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see what information has been logged during the training process\n",
    "plt.plot(simple_nn.history.history['loss'])\n",
    "plt.plot(simple_nn.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../dataset/simple_nn_model\\assets\n",
      "Storing the fitting history of simple nn to disk\n"
     ]
    }
   ],
   "source": [
    "# save the above simple nn fitted model to look at it later. We need to use the keras save command\n",
    "# this command will save all the components of the model, in particular the architecture and the weights\n",
    "# note: it will NOT save the training history. This needs to be saved separately.\n",
    "simple_nn.save('../dataset/simple_nn_model')\n",
    "\n",
    "print(\"Storing the fitting history of simple nn to disk\")\n",
    "with open('../dataset/simple_nn_history.json', 'w') as handle:\n",
    "    json.dump(simple_nn.history.history, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/simplen_nn_history.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16556/2773909162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#reload the fitting history like this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../dataset/simplen_nn_history.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0msimple_nn_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/simplen_nn_history.json'"
     ]
    }
   ],
   "source": [
    "# we can load the above save model like this:\n",
    "simple_nn = keras.models.load_model(\"../dataset/simple_nn_model\")\n",
    "#simple_nn\n",
    "\n",
    "#reload the fitting history like this\n",
    "with open(\"../dataset/simplen_nn_history.json\", \"r\") as handle:\n",
    "    simple_nn_history = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182b68d7a90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE of the nn model is 144193519207.57736\n"
     ]
    }
   ],
   "source": [
    "# calculating the MSE\n",
    "final_nn = Sequential()\n",
    "final_nn.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "final_nn.add(Dense(1))\n",
    "final_nn.compile(loss=tensorflow.keras.losses.MeanSquaredError(), optimizer='sgd')\n",
    "final_nn.fit(X_train_validation, y_train_validation, epochs=3, batch_size = 20, verbose=0)\n",
    "y_hat_test_nn = final_nn.predict(X_test)\n",
    "y_hat_test_nn = np.where(y_hat_test_nn >= 0.5, 1, 0)\n",
    "print(\"The MSE of the nn model is {}\".format(metrics.mean_squared_error(y_test, y_hat_test_nn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates the model\n",
    "# note that we pass the number of neurons as a parameter to the network\n",
    "def create_model(neurons=1):\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(neurons, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "    nn_model.add(Dense(1))\n",
    "    nn_model.compile(loss='', optimizer='adam')\n",
    "    return nn_model\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# turn the keras model into a sklearn compatible model\n",
    "# note that the neurons parameter needs to be specified in the interface of KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, neurons=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10, 20]\n",
    "epochs = [100, 150]\n",
    "neurons = [10, 20, 30]\n",
    "params_grid = dict(batch_size=batch_size, epochs=epochs, neurons=neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [10, 20], 'epochs': [100, 150], 'neurons': [10, 20, 30]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing parameter options\n",
    "params_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PredefinedSplit to specify which observations are train and which are validation\n",
    "fold_index = PredefinedSplit([-1]* X_train.shape[0] + [0] * X_validation.shape[0])\n",
    "\n",
    "# define the parameter grid as a dictionary of lists, where the keys are the names of the parameters\n",
    "#param_grid = {'n_estimators': n_estimators.tolist(), 'max_depth': max_depth.tolist()}\n",
    "param_grid = [n_estimators,max_depth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform grid search with sklearn if needed, otherwise load the grid search already performed\n",
    "if os.path.exists(\"../dataset/nn_grid_search.pickle\") and USE_STORED_NN_HYPERTUNED_MODELS is True:\n",
    "    with open('../dataset/nn_grid_search.pickle', 'rb') as handle:\n",
    "        grid_search_nn = pickle.load(handle)\n",
    "else:\n",
    "    start_time = datetime.datetime.now()\n",
    "    grid_search_nn = GridSearchCV(estimator=model, param_grid=params_grid, n_jobs=-1, cv=fold_index)\n",
    "    grid_search_nn = grid_search_nn.fit(X_train_validation, y_train_validation)\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(f'hypertuning with sklearn grid search for neural networks complete in {round((end_time - start_time).seconds/60, 2)} minutes')\n",
    "        store the results of the grid search to disk\n",
    "with open('../dataset/nn_grid_search.pickle', 'wb') as handle:\n",
    "    pickle.dump(grid_search_nn, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameter combination is: {} with score: {}\".format(grid_search_nn.best_params_, grid_search_nn.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = create_model(20)\n",
    "best_model.fit(X_train_validation, y_train_validation, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = best_model.predict(X_test)\n",
    "y_hat_test = np.where(y_hat_test >= 0.5, 1, 0)\n",
    "f1_score(y_test, y_hat_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b1827d4b6462cc460901af0bc0d075c933010817877a813d51f78a107cbf6e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
