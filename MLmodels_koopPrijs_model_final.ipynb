{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning modelling for 'koopPrijs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is executed for the course of AI for Business, at the Amsterdam School of Applied Sciences in 2022. The purpose of the research is to to build and evaluate machine learning approaches to predict the price of a  house and the time to sale of a house. The dataset that is used to train and evaluate the models is scraped from the Dutch housing website Funda. In this notebook, two machine learning models will be tested and compared with each other to see what model predict the best result. The project is conducted and combined by Pim Doosje (500800438) and Joel Zelle (500763451).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing all outputs in this notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing prepared csv file\n",
    "df_cleaned = pd.read_csv('prepared_df2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking and final preparation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>soortWoning_cleaned</th>\n",
       "      <th>postcode_prepared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Topic 10</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>104</td>\n",
       "      <td>vrijstaande_woning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Topic 2</td>\n",
       "      <td>267500.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>113</td>\n",
       "      <td>appartement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>349000.0</td>\n",
       "      <td>1973</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>132</td>\n",
       "      <td>eengezinswoning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Topic 6</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>323</td>\n",
       "      <td>123</td>\n",
       "      <td>vrijstaande_woning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Topic 9</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>243</td>\n",
       "      <td>eengezinswoning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0 main_topic  koopPrijs  bouwjaar  indTuin  \\\n",
       "0             0           0   Topic 10   139000.0      1971        1   \n",
       "1             2           2    Topic 2   267500.0      2001        0   \n",
       "2             3           3    Topic 3   349000.0      1973        1   \n",
       "3             4           4    Topic 6   495000.0      1900        0   \n",
       "4             5           5    Topic 9   162500.0      1970        1   \n",
       "\n",
       "   aantalKamers  oppervlakte  Time_to_sell soortWoning_cleaned  \\\n",
       "0             3           62           104  vrijstaande_woning   \n",
       "1             3           70           113         appartement   \n",
       "2             5          144           132     eengezinswoning   \n",
       "3             8          323           123  vrijstaande_woning   \n",
       "4             4           68           243     eengezinswoning   \n",
       "\n",
       "   postcode_prepared  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  3  \n",
       "4                  4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the header of the cleaned csv header\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1             int64\n",
       "Unnamed: 0               int64\n",
       "main_topic              object\n",
       "koopPrijs              float64\n",
       "bouwjaar                 int64\n",
       "indTuin                  int64\n",
       "aantalKamers             int64\n",
       "oppervlakte              int64\n",
       "Time_to_sell             int64\n",
       "soortWoning_cleaned     object\n",
       "postcode_prepared        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing all data types and making sure that all of them are integers or float except the soortwoning which still has to be dummified\n",
    "df_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1           0\n",
       "Unnamed: 0             0\n",
       "main_topic             0\n",
       "koopPrijs              0\n",
       "bouwjaar               0\n",
       "indTuin                0\n",
       "aantalKamers           0\n",
       "oppervlakte            0\n",
       "Time_to_sell           0\n",
       "soortWoning_cleaned    0\n",
       "postcode_prepared      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 1 Unnamed column\n",
    "df_cleaned = df_cleaned.drop('Unnamed: 0.1', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last transformation to make the data set ready for modelling\n",
    "df= df_cleaned\n",
    "columns = ['koopPrijs', 'bouwjaar']\n",
    "for col in columns:\n",
    "    df[col] = df[col].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming df and renaming column\n",
    "df = df_cleaned.rename(columns={'Unnamed: 0': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>soortWoning_cleaned</th>\n",
       "      <th>postcode_prepared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Topic 10</td>\n",
       "      <td>139000</td>\n",
       "      <td>1971</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>104</td>\n",
       "      <td>vrijstaande_woning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Topic 2</td>\n",
       "      <td>267500</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>113</td>\n",
       "      <td>appartement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>349000</td>\n",
       "      <td>1973</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>144</td>\n",
       "      <td>132</td>\n",
       "      <td>eengezinswoning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Topic 6</td>\n",
       "      <td>495000</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>323</td>\n",
       "      <td>123</td>\n",
       "      <td>vrijstaande_woning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Topic 9</td>\n",
       "      <td>162500</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>243</td>\n",
       "      <td>eengezinswoning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id main_topic  koopPrijs  bouwjaar  indTuin  aantalKamers  oppervlakte  \\\n",
       "0   0   Topic 10     139000      1971        1             3           62   \n",
       "1   2    Topic 2     267500      2001        0             3           70   \n",
       "2   3    Topic 3     349000      1973        1             5          144   \n",
       "3   4    Topic 6     495000      1900        0             8          323   \n",
       "4   5    Topic 9     162500      1970        1             4           68   \n",
       "\n",
       "   Time_to_sell soortWoning_cleaned  postcode_prepared  \n",
       "0           104  vrijstaande_woning                  0  \n",
       "1           113         appartement                  1  \n",
       "2           132     eengezinswoning                  2  \n",
       "3           123  vrijstaande_woning                  3  \n",
       "4           243     eengezinswoning                  4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final check to see if the dataframe is correct\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the splitter to split the data set between training, testing and validation sets\n",
    "class TrainTestSplitter(object):\n",
    "    '''Class to perform the split of the data into train, test, and validation.\n",
    "    '''\n",
    "    def __init__(self, train_frac=0.8, validation_frac=0.2, seed=1234):\n",
    "        self.train_frac = train_frac\n",
    "        self.validation_frac = validation_frac\n",
    "        self.seed = seed\n",
    "\n",
    "    def split_train_test(self, df):\n",
    "        print(\"Generating the train/validation/test splits...\")\n",
    "        self.train_set = df.sample(frac=self.train_frac, random_state=self.seed)\n",
    "        self.test_set = df.loc[lambda x: ~x.id.isin(self.train_set.id)].reset_index(drop=True)\n",
    "        self.validation_set = self.train_set.sample(frac=self.validation_frac).reset_index(drop=True)\n",
    "        self.train_set = self.train_set.loc[lambda x: ~x.id.isin(self.validation_set.id)].reset_index(drop=True)\n",
    "        print(\"calculating the statistics...\")\n",
    "        print(\"split completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the train/validation/test splits...\n",
      "calculating the statistics...\n",
      "split completed\n"
     ]
    }
   ],
   "source": [
    "# create a fitting_splits object that will hold the train, validation, and test data\n",
    "fitting_splits = TrainTestSplitter()\n",
    "fitting_splits.split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130027, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(40633, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32507, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if they're devided correctly\n",
    "fitting_splits.train_set.shape\n",
    "fitting_splits.test_set.shape\n",
    "fitting_splits.validation_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation for the models: dummifying and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummify the soortWoning column, in the training set: from catagory to integer \n",
    "# this needs to be done, so the outcomes become numbers. Only numbers can be used in creating the model.\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "one_hot_encoder.fit(fitting_splits.train_set[['soortWoning_cleaned', 'main_topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['appartement', 'benedenwoning', 'bovenwoning', 'eengezinswoning',\n",
       "        'herenhuis', 'other', 'portiekflat', 'vrijstaande_woning'],\n",
       "       dtype=object),\n",
       " array(['Topic 1', 'Topic 10', 'Topic 2', 'Topic 3', 'Topic 4', 'Topic 5',\n",
       "        'Topic 6', 'Topic 7', 'Topic 8', 'Topic 9'], dtype=object)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['soortWoning_cleaned_appartement',\n",
       "       'soortWoning_cleaned_benedenwoning',\n",
       "       'soortWoning_cleaned_bovenwoning',\n",
       "       'soortWoning_cleaned_eengezinswoning',\n",
       "       'soortWoning_cleaned_herenhuis', 'soortWoning_cleaned_other',\n",
       "       'soortWoning_cleaned_portiekflat',\n",
       "       'soortWoning_cleaned_vrijstaande_woning', 'main_topic_Topic 1',\n",
       "       'main_topic_Topic 10', 'main_topic_Topic 2', 'main_topic_Topic 3',\n",
       "       'main_topic_Topic 4', 'main_topic_Topic 5', 'main_topic_Topic 6',\n",
       "       'main_topic_Topic 7', 'main_topic_Topic 8', 'main_topic_Topic 9'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>soortWoning_cleaned_bovenwoning</th>\n",
       "      <th>soortWoning_cleaned_eengezinswoning</th>\n",
       "      <th>soortWoning_cleaned_herenhuis</th>\n",
       "      <th>soortWoning_cleaned_other</th>\n",
       "      <th>soortWoning_cleaned_portiekflat</th>\n",
       "      <th>soortWoning_cleaned_vrijstaande_woning</th>\n",
       "      <th>main_topic_Topic 1</th>\n",
       "      <th>main_topic_Topic 10</th>\n",
       "      <th>main_topic_Topic 2</th>\n",
       "      <th>main_topic_Topic 3</th>\n",
       "      <th>main_topic_Topic 4</th>\n",
       "      <th>main_topic_Topic 5</th>\n",
       "      <th>main_topic_Topic 6</th>\n",
       "      <th>main_topic_Topic 7</th>\n",
       "      <th>main_topic_Topic 8</th>\n",
       "      <th>main_topic_Topic 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130022</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130023</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130024</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130025</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130026</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130027 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        soortWoning_cleaned_appartement  soortWoning_cleaned_benedenwoning  \\\n",
       "0                                   0.0                                0.0   \n",
       "1                                   1.0                                0.0   \n",
       "2                                   0.0                                0.0   \n",
       "3                                   0.0                                0.0   \n",
       "4                                   0.0                                0.0   \n",
       "...                                 ...                                ...   \n",
       "130022                              1.0                                0.0   \n",
       "130023                              0.0                                0.0   \n",
       "130024                              0.0                                0.0   \n",
       "130025                              0.0                                0.0   \n",
       "130026                              0.0                                0.0   \n",
       "\n",
       "        soortWoning_cleaned_bovenwoning  soortWoning_cleaned_eengezinswoning  \\\n",
       "0                                   0.0                                  1.0   \n",
       "1                                   0.0                                  0.0   \n",
       "2                                   0.0                                  1.0   \n",
       "3                                   0.0                                  1.0   \n",
       "4                                   0.0                                  1.0   \n",
       "...                                 ...                                  ...   \n",
       "130022                              0.0                                  0.0   \n",
       "130023                              0.0                                  1.0   \n",
       "130024                              0.0                                  1.0   \n",
       "130025                              1.0                                  0.0   \n",
       "130026                              0.0                                  1.0   \n",
       "\n",
       "        soortWoning_cleaned_herenhuis  soortWoning_cleaned_other  \\\n",
       "0                                 0.0                        0.0   \n",
       "1                                 0.0                        0.0   \n",
       "2                                 0.0                        0.0   \n",
       "3                                 0.0                        0.0   \n",
       "4                                 0.0                        0.0   \n",
       "...                               ...                        ...   \n",
       "130022                            0.0                        0.0   \n",
       "130023                            0.0                        0.0   \n",
       "130024                            0.0                        0.0   \n",
       "130025                            0.0                        0.0   \n",
       "130026                            0.0                        0.0   \n",
       "\n",
       "        soortWoning_cleaned_portiekflat  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "...                                 ...   \n",
       "130022                              0.0   \n",
       "130023                              0.0   \n",
       "130024                              0.0   \n",
       "130025                              0.0   \n",
       "130026                              0.0   \n",
       "\n",
       "        soortWoning_cleaned_vrijstaande_woning  main_topic_Topic 1  \\\n",
       "0                                          0.0                 0.0   \n",
       "1                                          0.0                 0.0   \n",
       "2                                          0.0                 1.0   \n",
       "3                                          0.0                 0.0   \n",
       "4                                          0.0                 0.0   \n",
       "...                                        ...                 ...   \n",
       "130022                                     0.0                 0.0   \n",
       "130023                                     0.0                 0.0   \n",
       "130024                                     0.0                 0.0   \n",
       "130025                                     0.0                 0.0   \n",
       "130026                                     0.0                 0.0   \n",
       "\n",
       "        main_topic_Topic 10  main_topic_Topic 2  main_topic_Topic 3  \\\n",
       "0                       0.0                 0.0                 0.0   \n",
       "1                       0.0                 0.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "...                     ...                 ...                 ...   \n",
       "130022                  0.0                 1.0                 0.0   \n",
       "130023                  1.0                 0.0                 0.0   \n",
       "130024                  0.0                 0.0                 0.0   \n",
       "130025                  0.0                 0.0                 0.0   \n",
       "130026                  1.0                 0.0                 0.0   \n",
       "\n",
       "        main_topic_Topic 4  main_topic_Topic 5  main_topic_Topic 6  \\\n",
       "0                      0.0                 0.0                 1.0   \n",
       "1                      1.0                 0.0                 0.0   \n",
       "2                      0.0                 0.0                 0.0   \n",
       "3                      0.0                 0.0                 1.0   \n",
       "4                      0.0                 0.0                 0.0   \n",
       "...                    ...                 ...                 ...   \n",
       "130022                 0.0                 0.0                 0.0   \n",
       "130023                 0.0                 0.0                 0.0   \n",
       "130024                 0.0                 0.0                 1.0   \n",
       "130025                 1.0                 0.0                 0.0   \n",
       "130026                 0.0                 0.0                 0.0   \n",
       "\n",
       "        main_topic_Topic 7  main_topic_Topic 8  main_topic_Topic 9  \n",
       "0                      0.0                 0.0                 0.0  \n",
       "1                      0.0                 0.0                 0.0  \n",
       "2                      0.0                 0.0                 0.0  \n",
       "3                      0.0                 0.0                 0.0  \n",
       "4                      0.0                 0.0                 1.0  \n",
       "...                    ...                 ...                 ...  \n",
       "130022                 0.0                 0.0                 0.0  \n",
       "130023                 0.0                 0.0                 0.0  \n",
       "130024                 0.0                 0.0                 0.0  \n",
       "130025                 0.0                 0.0                 0.0  \n",
       "130026                 0.0                 0.0                 0.0  \n",
       "\n",
       "[130027 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the encoder\n",
    "one_hot_encoder.categories_ \n",
    "encoded_names = one_hot_encoder.get_feature_names_out() \n",
    "encoded_names\n",
    "\n",
    "encoded_categories = one_hot_encoder.transform(fitting_splits.train_set[['soortWoning_cleaned', 'main_topic']]).toarray() \n",
    "df_encoded = pd.DataFrame(encoded_categories)\n",
    "df_encoded.columns = encoded_names\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>postcode_prepared</th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>...</th>\n",
       "      <th>main_topic_Topic 1</th>\n",
       "      <th>main_topic_Topic 10</th>\n",
       "      <th>main_topic_Topic 2</th>\n",
       "      <th>main_topic_Topic 3</th>\n",
       "      <th>main_topic_Topic 4</th>\n",
       "      <th>main_topic_Topic 5</th>\n",
       "      <th>main_topic_Topic 6</th>\n",
       "      <th>main_topic_Topic 7</th>\n",
       "      <th>main_topic_Topic 8</th>\n",
       "      <th>main_topic_Topic 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60594</td>\n",
       "      <td>395000</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>166</td>\n",
       "      <td>25</td>\n",
       "      <td>58570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76397</td>\n",
       "      <td>275000</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>179</td>\n",
       "      <td>73921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209175</td>\n",
       "      <td>297500</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>203331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70903</td>\n",
       "      <td>279000</td>\n",
       "      <td>1970</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>142</td>\n",
       "      <td>27</td>\n",
       "      <td>68627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184014</td>\n",
       "      <td>209000</td>\n",
       "      <td>1963</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>178820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130022</th>\n",
       "      <td>78244</td>\n",
       "      <td>275000</td>\n",
       "      <td>1931</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>53</td>\n",
       "      <td>75725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130023</th>\n",
       "      <td>5020</td>\n",
       "      <td>550000</td>\n",
       "      <td>1976</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>255</td>\n",
       "      <td>297</td>\n",
       "      <td>4735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130024</th>\n",
       "      <td>39590</td>\n",
       "      <td>189500</td>\n",
       "      <td>1979</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "      <td>13</td>\n",
       "      <td>38034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130025</th>\n",
       "      <td>109599</td>\n",
       "      <td>285000</td>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>29</td>\n",
       "      <td>106351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130026</th>\n",
       "      <td>127775</td>\n",
       "      <td>175000</td>\n",
       "      <td>1961</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>123922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130027 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  koopPrijs  bouwjaar  indTuin  aantalKamers  oppervlakte  \\\n",
       "0        60594     395000      2004        1             6          166   \n",
       "1        76397     275000      1980        0             4          121   \n",
       "2       209175     297500      1998        1             5          121   \n",
       "3        70903     279000      1970        1             5          142   \n",
       "4       184014     209000      1963        1             5           89   \n",
       "...        ...        ...       ...      ...           ...          ...   \n",
       "130022   78244     275000      1931        0             4          110   \n",
       "130023    5020     550000      1976        1             5          255   \n",
       "130024   39590     189500      1979        1             6          121   \n",
       "130025  109599     285000      1927        0             5          123   \n",
       "130026  127775     175000      1961        1             5           78   \n",
       "\n",
       "        Time_to_sell  postcode_prepared  soortWoning_cleaned_appartement  \\\n",
       "0                 25              58570                              0.0   \n",
       "1                179              73921                              1.0   \n",
       "2                  8             203331                              0.0   \n",
       "3                 27              68627                              0.0   \n",
       "4                 23             178820                              0.0   \n",
       "...              ...                ...                              ...   \n",
       "130022            53              75725                              1.0   \n",
       "130023           297               4735                              0.0   \n",
       "130024            13              38034                              0.0   \n",
       "130025            29             106351                              0.0   \n",
       "130026            39             123922                              0.0   \n",
       "\n",
       "        soortWoning_cleaned_benedenwoning  ...  main_topic_Topic 1  \\\n",
       "0                                     0.0  ...                 0.0   \n",
       "1                                     0.0  ...                 0.0   \n",
       "2                                     0.0  ...                 1.0   \n",
       "3                                     0.0  ...                 0.0   \n",
       "4                                     0.0  ...                 0.0   \n",
       "...                                   ...  ...                 ...   \n",
       "130022                                0.0  ...                 0.0   \n",
       "130023                                0.0  ...                 0.0   \n",
       "130024                                0.0  ...                 0.0   \n",
       "130025                                0.0  ...                 0.0   \n",
       "130026                                0.0  ...                 0.0   \n",
       "\n",
       "        main_topic_Topic 10  main_topic_Topic 2  main_topic_Topic 3  \\\n",
       "0                       0.0                 0.0                 0.0   \n",
       "1                       0.0                 0.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "...                     ...                 ...                 ...   \n",
       "130022                  0.0                 1.0                 0.0   \n",
       "130023                  1.0                 0.0                 0.0   \n",
       "130024                  0.0                 0.0                 0.0   \n",
       "130025                  0.0                 0.0                 0.0   \n",
       "130026                  1.0                 0.0                 0.0   \n",
       "\n",
       "        main_topic_Topic 4  main_topic_Topic 5  main_topic_Topic 6  \\\n",
       "0                      0.0                 0.0                 1.0   \n",
       "1                      1.0                 0.0                 0.0   \n",
       "2                      0.0                 0.0                 0.0   \n",
       "3                      0.0                 0.0                 1.0   \n",
       "4                      0.0                 0.0                 0.0   \n",
       "...                    ...                 ...                 ...   \n",
       "130022                 0.0                 0.0                 0.0   \n",
       "130023                 0.0                 0.0                 0.0   \n",
       "130024                 0.0                 0.0                 1.0   \n",
       "130025                 1.0                 0.0                 0.0   \n",
       "130026                 0.0                 0.0                 0.0   \n",
       "\n",
       "        main_topic_Topic 7  main_topic_Topic 8  main_topic_Topic 9  \n",
       "0                      0.0                 0.0                 0.0  \n",
       "1                      0.0                 0.0                 0.0  \n",
       "2                      0.0                 0.0                 0.0  \n",
       "3                      0.0                 0.0                 0.0  \n",
       "4                      0.0                 0.0                 1.0  \n",
       "...                    ...                 ...                 ...  \n",
       "130022                 0.0                 0.0                 0.0  \n",
       "130023                 0.0                 0.0                 0.0  \n",
       "130024                 0.0                 0.0                 0.0  \n",
       "130025                 0.0                 0.0                 0.0  \n",
       "130026                 0.0                 0.0                 0.0  \n",
       "\n",
       "[130027 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the non dummified soortWoning and topic column, and the adding the dummified array to the training dataset\n",
    "train_set = fitting_splits.train_set.drop(['soortWoning_cleaned', 'main_topic'], axis=1)\n",
    "train_set = pd.concat([train_set, df_encoded], axis=1)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the scaler\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparer(object):\n",
    "    def __init__(self, one_hot_encoder, standard_scaler):\n",
    "        self.one_hot_encoder = one_hot_encoder\n",
    "        self.standard_scaler = standard_scaler\n",
    "\n",
    "    def dummify(self, df):\n",
    "        vars_to_encode = ['soortWoning_cleaned', 'main_topic']\n",
    "        df_to_encode = df[vars_to_encode]\n",
    "        df_encoded = self.one_hot_encoder.transform(df_to_encode).toarray()\n",
    "        df_encoded = pd.DataFrame(df_encoded)\n",
    "        df_encoded.columns = self.one_hot_encoder.get_feature_names_out()\n",
    "        # add the encoded columns and drop the original columns\n",
    "        df = df.drop(vars_to_encode,axis=1)\n",
    "        df = pd.concat([df, df_encoded], axis=1)\n",
    "        return df\n",
    "\n",
    "    def scale(self, df):\n",
    "        cols = df.columns\n",
    "        df = self.standard_scaler.transform(df)\n",
    "        df = pd.DataFrame(df)\n",
    "        df.columns = cols\n",
    "        return df\n",
    "\n",
    "    def prepare_data(self, df):\n",
    "        df = df.reset_index(drop=True)\n",
    "        # first dummify the data\n",
    "        df = self.dummify(df)\n",
    "        # then scale it\n",
    "        df = self.scale(df)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>postcode_prepared</th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>...</th>\n",
       "      <th>main_topic_Topic 1</th>\n",
       "      <th>main_topic_Topic 10</th>\n",
       "      <th>main_topic_Topic 2</th>\n",
       "      <th>main_topic_Topic 3</th>\n",
       "      <th>main_topic_Topic 4</th>\n",
       "      <th>main_topic_Topic 5</th>\n",
       "      <th>main_topic_Topic 6</th>\n",
       "      <th>main_topic_Topic 7</th>\n",
       "      <th>main_topic_Topic 8</th>\n",
       "      <th>main_topic_Topic 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.747856</td>\n",
       "      <td>0.372573</td>\n",
       "      <td>0.787243</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.855258</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>-0.540371</td>\n",
       "      <td>-0.748392</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>3.610083</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.488208</td>\n",
       "      <td>-0.225398</td>\n",
       "      <td>0.159442</td>\n",
       "      <td>-1.572088</td>\n",
       "      <td>-0.424642</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>1.631204</td>\n",
       "      <td>-0.489371</td>\n",
       "      <td>1.986517</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>2.416147</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.693373</td>\n",
       "      <td>-0.113278</td>\n",
       "      <td>0.630293</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>0.021825</td>\n",
       "      <td>-0.780090</td>\n",
       "      <td>1.694196</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047373</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.578476</td>\n",
       "      <td>-0.205466</td>\n",
       "      <td>-0.102142</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>0.453959</td>\n",
       "      <td>-0.512168</td>\n",
       "      <td>-0.578698</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>3.610083</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279970</td>\n",
       "      <td>-0.554282</td>\n",
       "      <td>-0.285251</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>-0.636664</td>\n",
       "      <td>-0.568573</td>\n",
       "      <td>1.280616</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>2.737325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  koopPrijs  bouwjaar   indTuin  aantalKamers  oppervlakte  \\\n",
       "0 -0.747856   0.372573  0.787243  0.636097      0.855258     0.947826   \n",
       "1 -0.488208  -0.225398  0.159442 -1.572088     -0.424642     0.021825   \n",
       "2  1.693373  -0.113278  0.630293  0.636097      0.215308     0.021825   \n",
       "3 -0.578476  -0.205466 -0.102142  0.636097      0.215308     0.453959   \n",
       "4  1.279970  -0.554282 -0.285251  0.636097      0.215308    -0.636664   \n",
       "\n",
       "   Time_to_sell  postcode_prepared  soortWoning_cleaned_appartement  \\\n",
       "0     -0.540371          -0.748392                        -0.503394   \n",
       "1      1.631204          -0.489371                         1.986517   \n",
       "2     -0.780090           1.694196                        -0.503394   \n",
       "3     -0.512168          -0.578698                        -0.503394   \n",
       "4     -0.568573           1.280616                        -0.503394   \n",
       "\n",
       "   soortWoning_cleaned_benedenwoning  ...  main_topic_Topic 1  \\\n",
       "0                          -0.080394  ...           -0.488431   \n",
       "1                          -0.080394  ...           -0.488431   \n",
       "2                          -0.080394  ...            2.047373   \n",
       "3                          -0.080394  ...           -0.488431   \n",
       "4                          -0.080394  ...           -0.488431   \n",
       "\n",
       "   main_topic_Topic 10  main_topic_Topic 2  main_topic_Topic 3  \\\n",
       "0            -0.462323           -0.175984           -0.241133   \n",
       "1            -0.462323           -0.175984           -0.241133   \n",
       "2            -0.462323           -0.175984           -0.241133   \n",
       "3            -0.462323           -0.175984           -0.241133   \n",
       "4            -0.462323           -0.175984           -0.241133   \n",
       "\n",
       "   main_topic_Topic 4  main_topic_Topic 5  main_topic_Topic 6  \\\n",
       "0           -0.413882           -0.319153            3.610083   \n",
       "1            2.416147           -0.319153           -0.277002   \n",
       "2           -0.413882           -0.319153           -0.277002   \n",
       "3           -0.413882           -0.319153            3.610083   \n",
       "4           -0.413882           -0.319153           -0.277002   \n",
       "\n",
       "   main_topic_Topic 7  main_topic_Topic 8  main_topic_Topic 9  \n",
       "0           -0.239845           -0.261929           -0.365320  \n",
       "1           -0.239845           -0.261929           -0.365320  \n",
       "2           -0.239845           -0.261929           -0.365320  \n",
       "3           -0.239845           -0.261929           -0.365320  \n",
       "4           -0.239845           -0.261929            2.737325  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>koopPrijs</th>\n",
       "      <th>bouwjaar</th>\n",
       "      <th>indTuin</th>\n",
       "      <th>aantalKamers</th>\n",
       "      <th>oppervlakte</th>\n",
       "      <th>Time_to_sell</th>\n",
       "      <th>postcode_prepared</th>\n",
       "      <th>soortWoning_cleaned_appartement</th>\n",
       "      <th>soortWoning_cleaned_benedenwoning</th>\n",
       "      <th>...</th>\n",
       "      <th>main_topic_Topic 1</th>\n",
       "      <th>main_topic_Topic 10</th>\n",
       "      <th>main_topic_Topic 2</th>\n",
       "      <th>main_topic_Topic 3</th>\n",
       "      <th>main_topic_Topic 4</th>\n",
       "      <th>main_topic_Topic 5</th>\n",
       "      <th>main_topic_Topic 6</th>\n",
       "      <th>main_topic_Topic 7</th>\n",
       "      <th>main_topic_Topic 8</th>\n",
       "      <th>main_topic_Topic 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.808878</td>\n",
       "      <td>-0.349975</td>\n",
       "      <td>0.499501</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>0.412803</td>\n",
       "      <td>-0.357056</td>\n",
       "      <td>-0.809929</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047373</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002252</td>\n",
       "      <td>-0.424722</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>-0.427561</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047373</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.591683</td>\n",
       "      <td>3.387345</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>2.614626</td>\n",
       "      <td>1.772215</td>\n",
       "      <td>-1.588629</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>2.737325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.287249</td>\n",
       "      <td>1.144953</td>\n",
       "      <td>-2.456398</td>\n",
       "      <td>-1.572088</td>\n",
       "      <td>2.775108</td>\n",
       "      <td>2.264804</td>\n",
       "      <td>-0.469865</td>\n",
       "      <td>-0.288073</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>2.162991</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.190886</td>\n",
       "      <td>-0.387349</td>\n",
       "      <td>0.054808</td>\n",
       "      <td>0.636097</td>\n",
       "      <td>0.215308</td>\n",
       "      <td>-0.060486</td>\n",
       "      <td>-0.667281</td>\n",
       "      <td>-0.190984</td>\n",
       "      <td>-0.503394</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488431</td>\n",
       "      <td>-0.462323</td>\n",
       "      <td>-0.175984</td>\n",
       "      <td>-0.241133</td>\n",
       "      <td>-0.413882</td>\n",
       "      <td>-0.319153</td>\n",
       "      <td>-0.277002</td>\n",
       "      <td>-0.239845</td>\n",
       "      <td>3.817830</td>\n",
       "      <td>-0.365320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  koopPrijs  bouwjaar   indTuin  aantalKamers  oppervlakte  \\\n",
       "0 -0.808878  -0.349975  0.499501  0.636097      0.215308     0.412803   \n",
       "1  0.002252  -0.424722  0.002491  0.636097      0.215308     0.762626   \n",
       "2 -1.591683   3.387345 -0.546835  0.636097      0.215308     2.614626   \n",
       "3 -0.287249   1.144953 -2.456398 -1.572088      2.775108     2.264804   \n",
       "4 -0.190886  -0.387349  0.054808  0.636097      0.215308    -0.060486   \n",
       "\n",
       "   Time_to_sell  postcode_prepared  soortWoning_cleaned_appartement  \\\n",
       "0     -0.357056          -0.809929                        -0.503394   \n",
       "1     -0.427561           0.002603                        -0.503394   \n",
       "2      1.772215          -1.588629                        -0.503394   \n",
       "3     -0.469865          -0.288073                        -0.503394   \n",
       "4     -0.667281          -0.190984                        -0.503394   \n",
       "\n",
       "   soortWoning_cleaned_benedenwoning  ...  main_topic_Topic 1  \\\n",
       "0                          -0.080394  ...            2.047373   \n",
       "1                          -0.080394  ...            2.047373   \n",
       "2                          -0.080394  ...           -0.488431   \n",
       "3                          -0.080394  ...           -0.488431   \n",
       "4                          -0.080394  ...           -0.488431   \n",
       "\n",
       "   main_topic_Topic 10  main_topic_Topic 2  main_topic_Topic 3  \\\n",
       "0            -0.462323           -0.175984           -0.241133   \n",
       "1            -0.462323           -0.175984           -0.241133   \n",
       "2            -0.462323           -0.175984           -0.241133   \n",
       "3             2.162991           -0.175984           -0.241133   \n",
       "4            -0.462323           -0.175984           -0.241133   \n",
       "\n",
       "   main_topic_Topic 4  main_topic_Topic 5  main_topic_Topic 6  \\\n",
       "0           -0.413882           -0.319153           -0.277002   \n",
       "1           -0.413882           -0.319153           -0.277002   \n",
       "2           -0.413882           -0.319153           -0.277002   \n",
       "3           -0.413882           -0.319153           -0.277002   \n",
       "4           -0.413882           -0.319153           -0.277002   \n",
       "\n",
       "   main_topic_Topic 7  main_topic_Topic 8  main_topic_Topic 9  \n",
       "0           -0.239845           -0.261929           -0.365320  \n",
       "1           -0.239845           -0.261929           -0.365320  \n",
       "2           -0.239845           -0.261929            2.737325  \n",
       "3           -0.239845           -0.261929           -0.365320  \n",
       "4           -0.239845            3.817830           -0.365320  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying one hot encoder and standard scaler and checking if it went correctly\n",
    "data_preparer = DataPreparer(one_hot_encoder, standard_scaler)\n",
    "data_preparer.prepare_data(fitting_splits.train_set).head()\n",
    "data_preparer.prepare_data(fitting_splits.validation_set).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training sets, without the the target 'koopPrijs' which is going to measure the buying price. The 'id' column is also taken out, as it has no additional value to the model.\n",
    "train_set_transformed = data_preparer.prepare_data(fitting_splits.train_set)\n",
    "X_train = train_set_transformed.drop(['koopPrijs', 'id'], axis=1) # need to drop the target! otherwise data leakage\n",
    "y_train = fitting_splits.train_set['koopPrijs'] # take it from the original untransformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can use the fitted random tree model to predict on the test dataset\n",
    "X_test = data_preparer.prepare_data(fitting_splits.test_set).drop(['koopPrijs', 'id'], axis=1)\n",
    "y_test = fitting_splits.test_set['koopPrijs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most suitable hyperparameters for the Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'squared_error',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# overview off all hyperparameters for the Randomforest model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 20, 30, 40, 50], 'n_estimators': [50, 100, 150, 200]}\n"
     ]
    }
   ],
   "source": [
    "# creating a grid from the hypertuning parameters\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 4)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin hypertuning\n",
      "fitting model for n_estimators: 50 and max_depth: 10\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 50 and max_depth: 20\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 50 and max_depth: 30\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 50 and max_depth: 40\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 50 and max_depth: 50\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 100 and max_depth: 10\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 100 and max_depth: 20\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 100 and max_depth: 30\n",
      "fitting complete.\n",
      "fitting model for n_estimators: 100 and max_depth: 40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pimdo\\OneDrive\\Documenten\\HvA\\Master\\Blok 2\\AI for Business\\Final_koopPrijs_model.ipynb Cell 28'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m depth \u001b[39min\u001b[39;00m max_depth:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=15'>16</a>\u001b[0m     \u001b[39m# fit a model with the given hyperparameter values.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=16'>17</a>\u001b[0m     \u001b[39m# A new model will be fitted for each loop cycle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfitting model for n_estimators: \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m and max_depth: \u001b[39m\u001b[39m{\u001b[39;00mdepth\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=18'>19</a>\u001b[0m     fitted_model \u001b[39m=\u001b[39m fit_RF_model(X_train, y_train, n, depth)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfitting complete.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=20'>21</a>\u001b[0m     \u001b[39m# store the fitted model in the fitted_model list\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\pimdo\\OneDrive\\Documenten\\HvA\\Master\\Blok 2\\AI for Business\\Final_koopPrijs_model.ipynb Cell 28'\u001b[0m in \u001b[0;36mfit_RF_model\u001b[1;34m(X_train, y_train, n, depth)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=3'>4</a>\u001b[0m simple_RF \u001b[39m=\u001b[39m RandomForestRegressor(random_state\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m, n_estimators\u001b[39m=\u001b[39mn, max_depth\u001b[39m=\u001b[39mdepth)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=4'>5</a>\u001b[0m \u001b[39m# fit the model instance on X_train\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=5'>6</a>\u001b[0m simple_RF\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX_train, y\u001b[39m=\u001b[39;49my_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pimdo/OneDrive/Documenten/HvA/Master/Blok%202/AI%20for%20Business/Final_koopPrijs_model.ipynb#ch0000027?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m simple_RF\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=438'>439</a>\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=439'>440</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=440'>441</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=441'>442</a>\u001b[0m ]\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=443'>444</a>\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=444'>445</a>\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=445'>446</a>\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=446'>447</a>\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=447'>448</a>\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=448'>449</a>\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=449'>450</a>\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=450'>451</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=451'>452</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=452'>453</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=453'>454</a>\u001b[0m )(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=454'>455</a>\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=455'>456</a>\u001b[0m         t,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=456'>457</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=457'>458</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=458'>459</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=459'>460</a>\u001b[0m         sample_weight,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=460'>461</a>\u001b[0m         i,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=461'>462</a>\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=462'>463</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=463'>464</a>\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=464'>465</a>\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=465'>466</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=466'>467</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=467'>468</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=469'>470</a>\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=470'>471</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=181'>182</a>\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=182'>183</a>\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=184'>185</a>\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=185'>186</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/ensemble/_forest.py?line=186'>187</a>\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1277'>1278</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1278'>1279</a>\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1279'>1280</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1280'>1281</a>\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1281'>1282</a>\u001b[0m \n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1282'>1283</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1311'>1312</a>\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1312'>1313</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1314'>1315</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1315'>1316</a>\u001b[0m         X,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1316'>1317</a>\u001b[0m         y,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1317'>1318</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1318'>1319</a>\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1319'>1320</a>\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1320'>1321</a>\u001b[0m     )\n\u001b[0;32m   <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=1321'>1322</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AIcourse\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=408'>409</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=409'>410</a>\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=410'>411</a>\u001b[0m         splitter,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=411'>412</a>\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=416'>417</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=417'>418</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=419'>420</a>\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=421'>422</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///~/anaconda3/envs/AIcourse/lib/site-packages/sklearn/tree/_classes.py?line=422'>423</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "def fit_RF_model(X_train, y_train, n, depth):\n",
    "    # create the model instance with the required parameters\n",
    "    simple_RF = RandomForestRegressor(random_state=1234, n_estimators=n, max_depth=depth)\n",
    "    # fit the model instance on X_train\n",
    "    simple_RF.fit(X=X_train, y=y_train)\n",
    "    return simple_RF\n",
    "\n",
    " # will hold the models fitted on train, for each hyperparameter combination\n",
    "fitted_models = []\n",
    "\n",
    "# train a model for each hyperparameter combination\n",
    "print(\"begin hypertuning\")\n",
    "for n in n_estimators:\n",
    "    for depth in max_depth:\n",
    "        # fit a model with the given hyperparameter values.\n",
    "        # A new model will be fitted for each loop cycle\n",
    "        print(f\"fitting model for n_estimators: {n} and max_depth: {depth}\")\n",
    "        fitted_model = fit_RF_model(X_train, y_train, n, depth)\n",
    "        print(f\"fitting complete.\")\n",
    "        # store the fitted model in the fitted_model list\n",
    "        fitted_models.append(fitted_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestRegressor(max_depth=10, n_estimators=50, random_state=1234),\n",
       " RandomForestRegressor(max_depth=20, n_estimators=50, random_state=1234),\n",
       " RandomForestRegressor(max_depth=30, n_estimators=50, random_state=1234),\n",
       " RandomForestRegressor(max_depth=40, n_estimators=50, random_state=1234)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the first four models\n",
    "fitted_models[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training and validation splits and defining measurement score: mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define validation set and put train & validation sets together\n",
    "X_validation = data_preparer.prepare_data(fitting_splits.validation_set).drop(['koopPrijs', 'id'], axis=1)\n",
    "y_validation = fitting_splits.validation_set['koopPrijs']\n",
    "X_train_validation = pd.concat([X_train, X_validation])\n",
    "y_train_validation = pd.concat([y_train, fitting_splits.validation_set['koopPrijs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining MAPE function\n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "mape_scores = []\n",
    "#Run the different combinations of hyper parameters through the validation set\n",
    "for m in fitted_models:\n",
    "    y_hat = m.predict(X_validation)\n",
    "    mape_score = MAPE(y_validation, y_hat)\n",
    "    mape_scores.append(mape_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24.28682586402575,\n",
       " 23.623932619893242,\n",
       " 23.83007355776773,\n",
       " 23.844476847007197,\n",
       " 23.846646698000956,\n",
       " 24.273833171823103,\n",
       " 23.532035658058568,\n",
       " 23.694846289247938,\n",
       " 23.71488826310744,\n",
       " 23.70083306248642,\n",
       " 24.26775552091805,\n",
       " 23.504358526680715,\n",
       " 23.65102318354856,\n",
       " 23.675055305990703,\n",
       " 23.665331898749297,\n",
       " 24.269037420252513,\n",
       " 23.49873283912729,\n",
       " 23.64740167340209,\n",
       " 23.663809927126287,\n",
       " 23.6559439267103]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the first 20 MAPE scores\n",
    "mape_scores[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best MAPE from the hypertuning\n",
    "max_mape_scores = max(mape_scores)\n",
    "best_model_index = mape_scores.index(max_mape_scores)\n",
    "best_model = fitted_models[best_model_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model and final outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value of n estimators found is 50\n",
      "The best value of max depth is 10\n"
     ]
    }
   ],
   "source": [
    "# printing best parameters\n",
    "print(f\"The best value of n estimators found is {best_model.n_estimators}\")\n",
    "print(f\"The best value of max depth is {best_model.max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, n_estimators=50, random_state=1234)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting model with best parameters, by training on the train+validation set\n",
    "selected_model = RandomForestRegressor(n_estimators = best_model.n_estimators, max_depth = best_model.max_depth, random_state=1234)\n",
    "selected_model.fit(X_train_validation, y_train_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.35800230700906\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set with the fitted model to get the final performance measure\n",
    "X_test = data_preparer.prepare_data(fitting_splits.test_set).drop(['koopPrijs', 'id'],axis=1)\n",
    "y_test = fitting_splits.test_set['koopPrijs']\n",
    "\n",
    "y_hat_final = selected_model.predict(X_test)\n",
    "mape_score_final = MAPE(y_test, y_hat_final)\n",
    "print(mape_score_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries for the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.7.0\n",
      "keras: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "import tensorflow\n",
    "print('tensorflow: %s' % tensorflow.__version__)\n",
    "import keras\n",
    "print('keras: %s' % keras.__version__)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasRegressor \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the characteristics of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of neurons for the input layer must be: 24\n"
     ]
    }
   ],
   "source": [
    "# printing amount of neurons for the input layer\n",
    "print(f\"The number of neurons for the input layer must be: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network model class instance\n",
    "simple_nn = Sequential()\n",
    "# set first layer ((input layer/2) + 2)\n",
    "simple_nn.add(Dense(14, input_dim=X_train.shape[1], activation='relu'))\n",
    "# set second layer\n",
    "simple_nn.add(Dense(14, activation='relu'))\n",
    "# add the output layer \n",
    "simple_nn.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 14)                350       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 14)                210       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 575\n",
      "Trainable params: 575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(simple_nn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting MAPE as loss function for the regression problem\n",
    "simple_nn.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130027, 24)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(130027,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32507, 24)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(32507,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shapes of arrays \n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_validation.shape\n",
    "y_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    }
   ],
   "source": [
    "# running the model\n",
    "simple_nn.fit(X_train, y_train, epochs=150, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_percentage_error'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2c8941ad4c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWOUlEQVR4nO3df4xdZ33n8feHiQNDoDg/Bm9i0zo0WbP82MR0hMiGVm0CNVBEvJRNg6KutxtttFXVJgW5xIu0LFWlhnV3KdmlbL1Q6q4CJE2NEwU1TtYJdKVdhY5xEucHbgIkkMmvocpACyPkmO/+cc8k48mMPWP7zL2e835JV/ee555z73eOfT/nmeeceW6qCklSd7yk3wVIkpaWwS9JHWPwS1LHGPyS1DEGvyR1zEn9LmAhzjjjjFq7dm2/y5CkE8qePXu+V1Ujs9tPiOBfu3YtY2Nj/S5Dkk4oSR6bq92hHknqGINfkjrG4JekjjH4JaljDH5J6pgT4qqeo7Fz7zhbd+3nickpzlo5zOYN69i4fnW/y5KkvluWwb9z7zhbduxj6sBBAMYnp9iyYx+A4S+p85blUM/WXfufD/1pUwcOsnXX/j5VJEmDY1kG/xOTU4tql6QuWZbBf9bK4UW1S1KXLMvg37xhHcMrhg5pG14xxOYN6/pUkSQNjmV5cnf6BK5X9UjSiy3L4Ide+Bv0kvRiy3KoR5I0P4NfkjrG4JekjjH4JaljDH5J6hiDX5I6ptXgT3JVkvuTPJDk6qbttCR3JHm4uT+1zRokSYdqLfiTvBH4d8BbgPOA9yQ5B7gG2F1V5wK7m2VJ0hJps8f/z4C7q+pHVfUc8FXgfcAlwPZmne3AxhZrkCTN0mbw3w/8fJLTk7wceDfwGmBVVT3ZrPMUsGqujZNcmWQsydjExESLZUpSt7QW/FX1EPBx4HbgNuAe4OCsdQqoebbfVlWjVTU6MjLSVpmS1Dmtntytqs9W1c9V1S8AzwJ/Bzyd5EyA5v6ZNmuQJB2q7at6Xt3c/zS98f3PA7cAm5pVNgE3t1mDJOlQbc/O+VdJTgcOAL9VVZNJrgVuTHIF8Bhwacs1SJJmaDX4q+rn52j7e+DiNt9XkjQ//3JXkjrG4JekjjH4JaljDH5J6hiDX5I6xuCXpI4x+CWpYwx+SeoYg1+SOsbgl6SOMfglqWMMfknqGINfkjrG4JekjjH4JaljDH5J6hiDX5I6xuCXpI4x+CWpY1oN/iS/m+SBJPcn+UKSlyU5O8ndSR5JckOSk9usQZJ0qNaCP8lq4HeA0ap6IzAEXAZ8HPhEVZ0DPAtc0VYNkqQXa3uo5yRgOMlJwMuBJ4GLgJua57cDG1uuQZI0Q2vBX1XjwB8B36EX+N8H9gCTVfVcs9rjwOq5tk9yZZKxJGMTExNtlSlJndPmUM+pwCXA2cBZwCnAOxe6fVVtq6rRqhodGRlpqUpJ6p42h3reDny7qiaq6gCwA7gQWNkM/QCsAcZbrEGSNEubwf8d4K1JXp4kwMXAg8BdwPubdTYBN7dYgyRpljbH+O+mdxL368C+5r22AR8GPpjkEeB04LNt1SBJerGTjrzK0auqjwIfndX8LeAtbb6vJGl+/uWuJHWMwS9JHWPwS1LHGPyS1DEGvyR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMQa/JHWMwS9JHWPwS1LHGPyS1DEGvyR1jMEvSR3T6lcvDoKde8fZums/T0xOcdbKYTZvWMfG9av7XZYk9U1rPf4k65LcM+P2gyRXJzktyR1JHm7uT22rhp17x9myYx/jk1MUMD45xZYd+9i5d7ytt5Skgdda8FfV/qo6v6rOB34O+BHwJeAaYHdVnQvsbpZbsXXXfqYOHDykberAQbbu2t/WW0rSwFuqMf6LgW9W1WPAJcD2pn07sLGtN31icmpR7ZLUBUsV/JcBX2ger6qqJ5vHTwGr5togyZVJxpKMTUxMHNWbnrVyeFHtktQFrQd/kpOB9wJ/Ofu5qiqg5tquqrZV1WhVjY6MjBzVe2/esI7hFUOHtA2vGGLzhnVH9XqStBwsxVU97wK+XlVPN8tPJzmzqp5McibwTFtvPH31jlf1SNILliL4P8ALwzwAtwCbgGub+5vbfPON61cb9JI0Q6tDPUlOAd4B7JjRfC3wjiQPA29vliVJS6TVHn9V/RA4fVbb39O7ykeS1AdO2SBJHWPwS1LHGPyS1DEGvyR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMQa/JHWMwS9JHWPwS1LHGPyS1DELCv4kpyR5SfP4nyZ5b5IV7ZYmSWrDQnv8fwO8LMlq4Hbg14E/b6soSVJ7Fhr8qaofAe8D/qSq/hXwhvbKkiS1ZcHBn+QC4HLgy03b0AI2WpnkpiTfSPJQkguSnJbkjiQPN/enHm3xkqTFW2jwXw1sAb5UVQ8keS1w1wK2+yRwW1W9DjgPeAi4BthdVecCu5tlSdISSVUtboPeSd5XVNUPjrDeq4B7gNfWjDdJsh/4xap6MsmZwFeqat3hXmt0dLTGxsYWVackdV2SPVU1Ort9oVf1fD7JTyU5BbgfeDDJ5iNsdjYwAXwuyd4kn2m2X1VVTzbrPAWsmuc9r0wylmRsYmJiIWVKkhZgoUM9r296+BuBv6YX6r9+hG1OAt4MfLqq1gM/ZNawTvObwJy/clTVtqoararRkZGRBZYpSTqShQb/iua6/Y3ALVV1gHkCe4bHgcer6u5m+SZ6B4KnmyEemvtnFl21JOmoLTT4/xR4FDgF+JskPwMcdoy/qp4Cvptkevz+YuBB4BZgU9O2Cbh5kTVLko7BSQtZqaquA66b0fRYkl9awKa/DVyf5GTgW8Bv0DvY3JjkCuAx4NLFlSxJOhYLCv7mCp2PAr/QNH0V+H3g+4fbrqruAV50Rple71+S1AcLHer5M+Af6PXOL6U3zPO5toqSJLVnQT1+4Ger6ldnLH8syT0t1CNJatlCe/xTSd42vZDkQmCqnZIkSW1aaI//3wN/0Yz1AzzLC1fmSJJOIAu9qude4LwkP9Us/yDJ1cB9LdYmSWrBor6Bq6p+MGOOng+2UI8kqWXH8tWLOW5VSJKWzLEE/+Km9ZQkDYTDjvEn+QfmDvgAw61UJElq1WGDv6peuVSFSJKWxrEM9UiSTkAGvyR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMQudj/+oJHmU3lc2HgSeq6rRJKcBNwBrgUeBS6vq2TbrkCS9YCl6/L9UVedX1fSXrl8D7K6qc4HdzXLrdu4d58Jr7+Tsa77Mhdfeyc6940vxtpI0cPox1HMJsL15vB3Y2PYb7tw7zpYd+xifnKKA8ckptuzYZ/hL6qS2g7+A25PsSXJl07aqqp5sHj8FrJprwyRXJhlLMjYxMXFMRWzdtZ+pAwcPaZs6cJCtu/Yf0+tK0omo1TF+4G1VNZ7k1cAdSb4x88mqqiRzzutfVduAbQCjo6PHNPf/E5Nzfy/8fO2StJy12uOvqvHm/hngS8BbgKeTnAnQ3D/TZg0AZ62c+6sD5muXpOWsteBPckqSV04/Bn4ZuB+4BdjUrLYJuLmtGqZt3rCO4RVDh7QNrxhi84Z1bb+1JA2cNod6VgFfSjL9Pp+vqtuS/C1wY5IrgMeAS1usAYCN61cDvbH+JyanOGvlMJs3rHu+XZK6JFWD/9W5o6OjNTY21u8yJOmEkmTPjEvpn+df7kpSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMQa/JHWMwS9JHWPwS1LHGPyS1DEGvyR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMa0Hf5KhJHuT3Nosn53k7iSPJLkhyclt1yBJesFS9PivAh6asfxx4BNVdQ7wLHDFEtQgSWq0GvxJ1gC/AnymWQ5wEXBTs8p2YGObNcy2c+84F157J2df82UuvPZOdu4dX8q3l6S+O6nl1/9j4PeAVzbLpwOTVfVcs/w4sLrlGp63c+84W3bsY+rAQQDGJ6fYsmMfABvXL1kZktRXrfX4k7wHeKaq9hzl9lcmGUsyNjExcVxq2rpr//OhP23qwEG27tp/XF5fkk4EbQ71XAi8N8mjwBfpDfF8EliZZPo3jTXAnGMtVbWtqkaranRkZOS4FPTE5NSi2iVpOWot+KtqS1Wtqaq1wGXAnVV1OXAX8P5mtU3AzW3VMNtZK4cX1S5Jy1E/ruP/MPDBJI/QG/P/7FK98eYN6xheMXRI2/CKITZvWLdUJUhS37V9cheAqvoK8JXm8beAtyzF+842fQJ36679PDE5xVkrh9m8YZ0ndiV1ypIE/yDZuH61QS+p05yyQZI6xuCXpI4x+CWpYwx+SeoYg1+SOsbgl6SO6dzlnNN27h33en5JndTJ4HeWTkld1smhHmfplNRlnQx+Z+mU1GWdDH5n6ZTUZZ0MfmfplNRlnTy56yydkrosVdXvGo5odHS0xsbGWnltL+uUtFwl2VNVo7PbO9njn+ZlnZK6qJNj/NO8rFNSF3U6+L2sU1IXdTr457t88yUJO/eOL3E1krQ0Wgv+JC9L8rUk9yZ5IMnHmvazk9yd5JEkNyQ5ua0ajmSuyzoBDlaxZcc+w1/SstRmj//HwEVVdR5wPvDOJG8FPg58oqrOAZ4FrmixhsPauH41f/i+NzGUvOi5qQMH+dCN9xr+kpad1oK/ev6xWVzR3Aq4CLipad8ObGyrhoXYuH41P5nnklZ7/pKWo1bH+JMMJbkHeAa4A/gmMFlVzzWrPA7Med1kkiuTjCUZm5iYaLPMw07VYM9f0nLTavBX1cGqOh9YA7wFeN0itt1WVaNVNToyMtJWicD8Y/3T7PlLWk6W5KqeqpoE7gIuAFYmmf7DsTVA39P0cGP90+z5S1ou2ryqZyTJyubxMPAO4CF6B4D3N6ttAm5uq4bF2Lh+Nf/l0vPs+Uta9tqcsuFMYHuSIXoHmBur6tYkDwJfTPIHwF7gsy3WsCjT0zR86MZ7OTjPCd/pnv/M9SXpRNL5SdrmMnsOn7mE3iVKq53YTdKAmm+Stk7/5e58FjLmP324HJ+c4uob7mH979/uEJCkE4LBP4+FjPnP9OyPDngAkHRCMPgPYyE9/9k8AEgadAb/ESy25z/NA4CkQeXJ3QWa/qau8cmp50/sLsZLAj8pTwZLWjrzndw1+I/Czr3j/KdbHmBy6sBRv4YHAkltM/hbcDwOANOmDwRDCQerPCBIOmYGf4uO5wFgttkHhMXeewCRusvgXwJtHgCO1ewDyMrhFSS9k9BHe1Dp1/1S1u6BUycyg38JDfIBQEfnWH/zWg4H3OXwM5yItR9L58Pg74NjvRJIkgCGVwzxh+9706LDf77gb3OSts7buH71If9QHggkHY2pAwfZumv/cRtyNPiX0OEOBNO/1nlAkDSXJyanjttrGfx9NPtAMG2uA8Ji7z2ASMvL4b4idrEM/gE03wFhsQ53ADkRT3ItZe0eODVIhlcMsXnDuuP2egb/Mna8DiBddTx+81pOB9zl8DOciLW3cUmxwS/NwwOnlitn55SkjjH4JaljDH5J6hiDX5I6xuCXpI45IebqSTIBPLbIzc4AvtdCOceTNR4fg17joNcH1ni8DFqNP1NVI7MbT4jgPxpJxuaanGiQWOPxMeg1Dnp9YI3Hy4lQIzjUI0mdY/BLUscs5+Df1u8CFsAaj49Br3HQ6wNrPF5OhBqX7xi/JGluy7nHL0mag8EvSR2zLIM/yTuT7E/ySJJrBqCe1yS5K8mDSR5IclXTflqSO5I83NyfOgC1DiXZm+TWZvnsJHc3+/KGJCf3ub6VSW5K8o0kDyW5YND2Y5Lfbf6d70/yhSQv6/d+TPJnSZ5Jcv+Mtjn3W3qua2q9L8mb+1jj1ubf+r4kX0qycsZzW5oa9yfZ0K8aZzz3oSSV5IxmuS/7cSGWXfAnGQI+BbwLeD3wgSSv729VPAd8qKpeD7wV+K2mpmuA3VV1LrC7We63q4CHZix/HPhEVZ0DPAtc0ZeqXvBJ4Laqeh1wHr1aB2Y/JlkN/A4wWlVvBIaAy+j/fvxz4J2z2ubbb+8Czm1uVwKf7mONdwBvrKp/DvwdsAWg+fxcBryh2eZPms9+P2okyWuAXwa+M6O5X/vxyKpqWd2AC4BdM5a3AFv6XdesGm8G3gHsB85s2s4E9ve5rjX0AuAi4FYg9P4K8aS59m0f6nsV8G2aixJmtA/MfgRWA98FTqP3fRe3AhsGYT8Ca4H7j7TfgD8FPjDXektd46zn/iVwffP4kM81sAu4oF81AjfR64g8CpzR7/14pNuy6/Hzwgdv2uNN20BIshZYD9wNrKqqJ5unngJW9auuxh8Dvwf8pFk+HZisquea5X7vy7OBCeBzzXDUZ5KcwgDtx6oaB/6IXs/vSeD7wB4Gaz9Om2+/Depn6N8Cf908Hpgak1wCjFfVvbOeGpgaZ1uOwT+wkrwC+Cvg6qr6wcznqtcl6Nu1tUneAzxTVXv6VcMCnAS8Gfh0Va0HfsisYZ0B2I+nApfQO0idBZzCHEMDg6bf++1IknyE3pDp9f2uZaYkLwf+A/Af+13LYizH4B8HXjNjeU3T1ldJVtAL/eurakfT/HSSM5vnzwSe6Vd9wIXAe5M8CnyR3nDPJ4GVSaa/orPf+/Jx4PGqurtZvonegWCQ9uPbgW9X1URVHQB20Nu3g7Qfp8233wbqM5Tk3wDvAS5vDlAwODX+LL2D/L3NZ2cN8PUk/4TBqfFFlmPw/y1wbnMVxcn0TgDd0s+CkgT4LPBQVf3XGU/dAmxqHm+iN/bfF1W1parWVNVaevvszqq6HLgLeH+zWr9rfAr4bpJ1TdPFwIMM0H6kN8Tz1iQvb/7dp2scmP04w3z77RbgXzdXpbwV+P6MIaElleSd9IYf31tVP5rx1C3AZUlemuRseidQv7bU9VXVvqp6dVWtbT47jwNvbv6vDsx+fJF+n2Ro4wa8m94VAN8EPjIA9byN3q/R9wH3NLd30xtD3w08DPxv4LR+19rU+4vArc3j19L7QD0C/CXw0j7Xdj4w1uzLncCpg7YfgY8B3wDuB/4X8NJ+70fgC/TOORygF05XzLff6J3U/1Tz+dlH7wqlftX4CL1x8unPzf+Ysf5Hmhr3A+/qV42znn+UF07u9mU/LuTmlA2S1DHLcahHknQYBr8kdYzBL0kdY/BLUscY/JLUMQa/BCQ5mOSeGbfjNtFbkrVzzeYo9ctJR15F6oSpqjq/30VIS8Eev3QYSR5N8p+T7EvytSTnNO1rk9zZzLO+O8lPN+2rmnnj721u/6J5qaEk/zO9efpvTzLctx9KnWfwSz3Ds4Z6fm3Gc9+vqjcB/53eDKYA/w3YXr154q8HrmvarwO+WlXn0ZtH6IGm/VzgU1X1BmAS+NVWfxrpMPzLXQlI8o9V9Yo52h8FLqqqbzUT7T1VVacn+R69udUPNO1PVtUZSSaANVX14xmvsRa4o3pfeEKSDwMrquoPluBHk17EHr90ZDXP48X48YzHB/H8mvrI4JeO7Ndm3P+/5vH/pTeLKcDlwP9pHu8GfhOe//7iVy1VkdJC2euQeoaT3DNj+baqmr6k89Qk99HrtX+gafttet8Etpnet4L9RtN+FbAtyRX0eva/SW82R2lgOMYvHUYzxj9aVd/rdy3S8eJQjyR1jD1+SeoYe/yS1DEGvyR1jMEvSR1j8EtSxxj8ktQx/x+Fdo5NqyLvvgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see what information has been logged during the training process\n",
    "simple_nn.history.history.keys()\n",
    "\n",
    "# plot the training loss over epochs\n",
    "loss_df = pd.DataFrame(simple_nn.history.history['loss'])\n",
    "loss_df.columns = ['loss']\n",
    "loss_df = loss_df.assign(epoch = np.arange(1, 151)) \n",
    "\n",
    "y = loss_df['loss']\n",
    "x = loss_df['epoch']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.6127 - mean_absolute_percentage_error: 23.6127 - val_loss: 22.7442 - val_mean_absolute_percentage_error: 22.7442\n",
      "Epoch 2/250\n",
      "4103/4103 [==============================] - 16s 4ms/step - loss: 23.6069 - mean_absolute_percentage_error: 23.6069 - val_loss: 22.7438 - val_mean_absolute_percentage_error: 22.7438\n",
      "Epoch 3/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.6100 - mean_absolute_percentage_error: 23.6100 - val_loss: 22.7408 - val_mean_absolute_percentage_error: 22.7408\n",
      "Epoch 4/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.6096 - mean_absolute_percentage_error: 23.6096 - val_loss: 22.7431 - val_mean_absolute_percentage_error: 22.7431\n",
      "Epoch 5/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.6089 - mean_absolute_percentage_error: 23.6089 - val_loss: 22.7422 - val_mean_absolute_percentage_error: 22.7422\n",
      "Epoch 6/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.6070 - mean_absolute_percentage_error: 23.6070 - val_loss: 22.7419 - val_mean_absolute_percentage_error: 22.7419\n",
      "Epoch 7/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.6072 - mean_absolute_percentage_error: 23.6072 - val_loss: 22.7438 - val_mean_absolute_percentage_error: 22.7438\n",
      "Epoch 8/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.6055 - mean_absolute_percentage_error: 23.6055 - val_loss: 22.7401 - val_mean_absolute_percentage_error: 22.7401\n",
      "Epoch 9/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.6090 - mean_absolute_percentage_error: 23.6090 - val_loss: 22.7427 - val_mean_absolute_percentage_error: 22.7427\n",
      "Epoch 10/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.6038 - mean_absolute_percentage_error: 23.6038 - val_loss: 22.7380 - val_mean_absolute_percentage_error: 22.7380\n",
      "Epoch 11/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.6080 - mean_absolute_percentage_error: 23.6080 - val_loss: 22.7411 - val_mean_absolute_percentage_error: 22.7411\n",
      "Epoch 12/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6066 - mean_absolute_percentage_error: 23.6066 - val_loss: 22.7390 - val_mean_absolute_percentage_error: 22.7390\n",
      "Epoch 13/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6044 - mean_absolute_percentage_error: 23.6044 - val_loss: 22.7364 - val_mean_absolute_percentage_error: 22.7364\n",
      "Epoch 14/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6059 - mean_absolute_percentage_error: 23.6059 - val_loss: 22.7374 - val_mean_absolute_percentage_error: 22.7374\n",
      "Epoch 15/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6048 - mean_absolute_percentage_error: 23.6048 - val_loss: 22.7431 - val_mean_absolute_percentage_error: 22.7431\n",
      "Epoch 16/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6032 - mean_absolute_percentage_error: 23.6032 - val_loss: 22.7431 - val_mean_absolute_percentage_error: 22.7431\n",
      "Epoch 17/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6005 - mean_absolute_percentage_error: 23.6005 - val_loss: 22.7348 - val_mean_absolute_percentage_error: 22.7348\n",
      "Epoch 18/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6030 - mean_absolute_percentage_error: 23.6030 - val_loss: 22.7343 - val_mean_absolute_percentage_error: 22.7343\n",
      "Epoch 19/250\n",
      "4103/4103 [==============================] - 14s 4ms/step - loss: 23.6040 - mean_absolute_percentage_error: 23.6040 - val_loss: 22.7341 - val_mean_absolute_percentage_error: 22.7341\n",
      "Epoch 20/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6054 - mean_absolute_percentage_error: 23.6054 - val_loss: 22.7337 - val_mean_absolute_percentage_error: 22.7337\n",
      "Epoch 21/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6009 - mean_absolute_percentage_error: 23.6009 - val_loss: 22.7343 - val_mean_absolute_percentage_error: 22.7343\n",
      "Epoch 22/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.6004 - mean_absolute_percentage_error: 23.6004 - val_loss: 22.7335 - val_mean_absolute_percentage_error: 22.7335\n",
      "Epoch 23/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.6038 - mean_absolute_percentage_error: 23.6038 - val_loss: 22.7363 - val_mean_absolute_percentage_error: 22.7363\n",
      "Epoch 24/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6019 - mean_absolute_percentage_error: 23.6019 - val_loss: 22.7382 - val_mean_absolute_percentage_error: 22.7382\n",
      "Epoch 25/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5988 - mean_absolute_percentage_error: 23.5988 - val_loss: 22.7328 - val_mean_absolute_percentage_error: 22.7328\n",
      "Epoch 26/250\n",
      "4103/4103 [==============================] - 14s 4ms/step - loss: 23.5973 - mean_absolute_percentage_error: 23.5973 - val_loss: 22.7401 - val_mean_absolute_percentage_error: 22.7401\n",
      "Epoch 27/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5994 - mean_absolute_percentage_error: 23.5994 - val_loss: 22.7446 - val_mean_absolute_percentage_error: 22.7446\n",
      "Epoch 28/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5967 - mean_absolute_percentage_error: 23.5967 - val_loss: 22.7400 - val_mean_absolute_percentage_error: 22.7400\n",
      "Epoch 29/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5959 - mean_absolute_percentage_error: 23.5959 - val_loss: 22.7317 - val_mean_absolute_percentage_error: 22.7317\n",
      "Epoch 30/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5989 - mean_absolute_percentage_error: 23.5989 - val_loss: 22.7309 - val_mean_absolute_percentage_error: 22.7309\n",
      "Epoch 31/250\n",
      "4103/4103 [==============================] - 14s 4ms/step - loss: 23.5995 - mean_absolute_percentage_error: 23.5995 - val_loss: 22.7336 - val_mean_absolute_percentage_error: 22.7336\n",
      "Epoch 32/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5968 - mean_absolute_percentage_error: 23.5968 - val_loss: 22.7312 - val_mean_absolute_percentage_error: 22.7312\n",
      "Epoch 33/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.6023 - mean_absolute_percentage_error: 23.6023 - val_loss: 22.7325 - val_mean_absolute_percentage_error: 22.7325\n",
      "Epoch 34/250\n",
      "4103/4103 [==============================] - 14s 4ms/step - loss: 23.5966 - mean_absolute_percentage_error: 23.5966 - val_loss: 22.7344 - val_mean_absolute_percentage_error: 22.7344\n",
      "Epoch 35/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5955 - mean_absolute_percentage_error: 23.5955 - val_loss: 22.7338 - val_mean_absolute_percentage_error: 22.7338\n",
      "Epoch 36/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5934 - mean_absolute_percentage_error: 23.5934 - val_loss: 22.7303 - val_mean_absolute_percentage_error: 22.7303\n",
      "Epoch 37/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5963 - mean_absolute_percentage_error: 23.5963 - val_loss: 22.7292 - val_mean_absolute_percentage_error: 22.7292\n",
      "Epoch 38/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5991 - mean_absolute_percentage_error: 23.5991 - val_loss: 22.7288 - val_mean_absolute_percentage_error: 22.7288\n",
      "Epoch 39/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5958 - mean_absolute_percentage_error: 23.5958 - val_loss: 22.7273 - val_mean_absolute_percentage_error: 22.7273\n",
      "Epoch 40/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5956 - mean_absolute_percentage_error: 23.5956 - val_loss: 22.7277 - val_mean_absolute_percentage_error: 22.7277\n",
      "Epoch 41/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5970 - mean_absolute_percentage_error: 23.5970 - val_loss: 22.7336 - val_mean_absolute_percentage_error: 22.7336\n",
      "Epoch 42/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5939 - mean_absolute_percentage_error: 23.5939 - val_loss: 22.7285 - val_mean_absolute_percentage_error: 22.7285\n",
      "Epoch 43/250\n",
      "4103/4103 [==============================] - 17s 4ms/step - loss: 23.5964 - mean_absolute_percentage_error: 23.5964 - val_loss: 22.7280 - val_mean_absolute_percentage_error: 22.7280\n",
      "Epoch 44/250\n",
      "4103/4103 [==============================] - 17s 4ms/step - loss: 23.5914 - mean_absolute_percentage_error: 23.5914 - val_loss: 22.7279 - val_mean_absolute_percentage_error: 22.7279\n",
      "Epoch 45/250\n",
      "4103/4103 [==============================] - 16s 4ms/step - loss: 23.5947 - mean_absolute_percentage_error: 23.5947 - val_loss: 22.7289 - val_mean_absolute_percentage_error: 22.7289\n",
      "Epoch 46/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5951 - mean_absolute_percentage_error: 23.5951 - val_loss: 22.7263 - val_mean_absolute_percentage_error: 22.7263\n",
      "Epoch 47/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5955 - mean_absolute_percentage_error: 23.5955 - val_loss: 22.7283 - val_mean_absolute_percentage_error: 22.7283\n",
      "Epoch 48/250\n",
      "4103/4103 [==============================] - 18s 4ms/step - loss: 23.5935 - mean_absolute_percentage_error: 23.5935 - val_loss: 22.7259 - val_mean_absolute_percentage_error: 22.7259\n",
      "Epoch 49/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5937 - mean_absolute_percentage_error: 23.5937 - val_loss: 22.7262 - val_mean_absolute_percentage_error: 22.7262\n",
      "Epoch 50/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5915 - mean_absolute_percentage_error: 23.5915 - val_loss: 22.7292 - val_mean_absolute_percentage_error: 22.7292\n",
      "Epoch 51/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5928 - mean_absolute_percentage_error: 23.5928 - val_loss: 22.7260 - val_mean_absolute_percentage_error: 22.7260\n",
      "Epoch 52/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5938 - mean_absolute_percentage_error: 23.5938 - val_loss: 22.7299 - val_mean_absolute_percentage_error: 22.7299\n",
      "Epoch 53/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5916 - mean_absolute_percentage_error: 23.5916 - val_loss: 22.7268 - val_mean_absolute_percentage_error: 22.7268\n",
      "Epoch 54/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5902 - mean_absolute_percentage_error: 23.5902 - val_loss: 22.7246 - val_mean_absolute_percentage_error: 22.7246\n",
      "Epoch 55/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5911 - mean_absolute_percentage_error: 23.5911 - val_loss: 22.7244 - val_mean_absolute_percentage_error: 22.7244\n",
      "Epoch 56/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5897 - mean_absolute_percentage_error: 23.5897 - val_loss: 22.7276 - val_mean_absolute_percentage_error: 22.7276\n",
      "Epoch 57/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5894 - mean_absolute_percentage_error: 23.5894 - val_loss: 22.7261 - val_mean_absolute_percentage_error: 22.7261\n",
      "Epoch 58/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5925 - mean_absolute_percentage_error: 23.5925 - val_loss: 22.7247 - val_mean_absolute_percentage_error: 22.7247\n",
      "Epoch 59/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5891 - mean_absolute_percentage_error: 23.5891 - val_loss: 22.7239 - val_mean_absolute_percentage_error: 22.7239\n",
      "Epoch 60/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5898 - mean_absolute_percentage_error: 23.5898 - val_loss: 22.7255 - val_mean_absolute_percentage_error: 22.7255\n",
      "Epoch 61/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5917 - mean_absolute_percentage_error: 23.5917 - val_loss: 22.7237 - val_mean_absolute_percentage_error: 22.7237\n",
      "Epoch 62/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5882 - mean_absolute_percentage_error: 23.5882 - val_loss: 22.7224 - val_mean_absolute_percentage_error: 22.7224tage_error:\n",
      "Epoch 63/250\n",
      "4103/4103 [==============================] - 16s 4ms/step - loss: 23.5890 - mean_absolute_percentage_error: 23.5890 - val_loss: 22.7236 - val_mean_absolute_percentage_error: 22.7236\n",
      "Epoch 64/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5891 - mean_absolute_percentage_error: 23.5891 - val_loss: 22.7239 - val_mean_absolute_percentage_error: 22.7239\n",
      "Epoch 65/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5901 - mean_absolute_percentage_error: 23.5901 - val_loss: 22.7233 - val_mean_absolute_percentage_error: 22.7233\n",
      "Epoch 66/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5906 - mean_absolute_percentage_error: 23.5906 - val_loss: 22.7295 - val_mean_absolute_percentage_error: 22.7295\n",
      "Epoch 67/250\n",
      "4103/4103 [==============================] - 10s 3ms/step - loss: 23.5845 - mean_absolute_percentage_error: 23.5845 - val_loss: 22.7250 - val_mean_absolute_percentage_error: 22.7250\n",
      "Epoch 68/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5875 - mean_absolute_percentage_error: 23.5875 - val_loss: 22.7269 - val_mean_absolute_percentage_error: 22.7269\n",
      "Epoch 69/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5919 - mean_absolute_percentage_error: 23.5919 - val_loss: 22.7251 - val_mean_absolute_percentage_error: 22.7251\n",
      "Epoch 70/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5843 - mean_absolute_percentage_error: 23.5843 - val_loss: 22.7483 - val_mean_absolute_percentage_error: 22.7483\n",
      "Epoch 71/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5896 - mean_absolute_percentage_error: 23.5896 - val_loss: 22.7236 - val_mean_absolute_percentage_error: 22.7236\n",
      "Epoch 72/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5866 - mean_absolute_percentage_error: 23.5866 - val_loss: 22.7229 - val_mean_absolute_percentage_error: 22.7229\n",
      "Epoch 73/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5883 - mean_absolute_percentage_error: 23.5883 - val_loss: 22.7221 - val_mean_absolute_percentage_error: 22.7221\n",
      "Epoch 74/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5856 - mean_absolute_percentage_error: 23.5856 - val_loss: 22.7212 - val_mean_absolute_percentage_error: 22.7212\n",
      "Epoch 75/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5870 - mean_absolute_percentage_error: 23.5870 - val_loss: 22.7213 - val_mean_absolute_percentage_error: 22.7213\n",
      "Epoch 76/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5873 - mean_absolute_percentage_error: 23.5873 - val_loss: 22.7208 - val_mean_absolute_percentage_error: 22.7208\n",
      "Epoch 77/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5861 - mean_absolute_percentage_error: 23.5861 - val_loss: 22.7203 - val_mean_absolute_percentage_error: 22.7203\n",
      "Epoch 78/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5870 - mean_absolute_percentage_error: 23.5870 - val_loss: 22.7225 - val_mean_absolute_percentage_error: 22.7225\n",
      "Epoch 79/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5869 - mean_absolute_percentage_error: 23.5869 - val_loss: 22.7222 - val_mean_absolute_percentage_error: 22.7222\n",
      "Epoch 80/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5872 - mean_absolute_percentage_error: 23.5872 - val_loss: 22.7211 - val_mean_absolute_percentage_error: 22.7211\n",
      "Epoch 81/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5870 - mean_absolute_percentage_error: 23.5870 - val_loss: 22.7226 - val_mean_absolute_percentage_error: 22.7226\n",
      "Epoch 82/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5864 - mean_absolute_percentage_error: 23.5864 - val_loss: 22.7214 - val_mean_absolute_percentage_error: 22.7214\n",
      "Epoch 83/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5854 - mean_absolute_percentage_error: 23.5854 - val_loss: 22.7275 - val_mean_absolute_percentage_error: 22.7275\n",
      "Epoch 84/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5845 - mean_absolute_percentage_error: 23.5845 - val_loss: 22.7203 - val_mean_absolute_percentage_error: 22.7203\n",
      "Epoch 85/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5887 - mean_absolute_percentage_error: 23.5887 - val_loss: 22.7229 - val_mean_absolute_percentage_error: 22.7229\n",
      "Epoch 86/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5872 - mean_absolute_percentage_error: 23.5872 - val_loss: 22.7227 - val_mean_absolute_percentage_error: 22.7227\n",
      "Epoch 87/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5864 - mean_absolute_percentage_error: 23.5864 - val_loss: 22.7202 - val_mean_absolute_percentage_error: 22.7202\n",
      "Epoch 88/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5828 - mean_absolute_percentage_error: 23.5828 - val_loss: 22.7216 - val_mean_absolute_percentage_error: 22.7216\n",
      "Epoch 89/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5877 - mean_absolute_percentage_error: 23.5877 - val_loss: 22.7201 - val_mean_absolute_percentage_error: 22.7201\n",
      "Epoch 90/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5852 - mean_absolute_percentage_error: 23.5852 - val_loss: 22.7187 - val_mean_absolute_percentage_error: 22.7187\n",
      "Epoch 91/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5818 - mean_absolute_percentage_error: 23.5818 - val_loss: 22.7191 - val_mean_absolute_percentage_error: 22.7191\n",
      "Epoch 92/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5864 - mean_absolute_percentage_error: 23.5864 - val_loss: 22.7232 - val_mean_absolute_percentage_error: 22.7232\n",
      "Epoch 93/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5854 - mean_absolute_percentage_error: 23.5854 - val_loss: 22.7193 - val_mean_absolute_percentage_error: 22.7193\n",
      "Epoch 94/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5853 - mean_absolute_percentage_error: 23.5853 - val_loss: 22.7270 - val_mean_absolute_percentage_error: 22.7270\n",
      "Epoch 95/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5822 - mean_absolute_percentage_error: 23.5822 - val_loss: 22.7183 - val_mean_absolute_percentage_error: 22.7183\n",
      "Epoch 96/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5862 - mean_absolute_percentage_error: 23.5862 - val_loss: 22.7185 - val_mean_absolute_percentage_error: 22.7185\n",
      "Epoch 97/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5826 - mean_absolute_percentage_error: 23.5826 - val_loss: 22.7191 - val_mean_absolute_percentage_error: 22.7191\n",
      "Epoch 98/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5849 - mean_absolute_percentage_error: 23.5849 - val_loss: 22.7217 - val_mean_absolute_percentage_error: 22.7217\n",
      "Epoch 99/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5831 - mean_absolute_percentage_error: 23.5831 - val_loss: 22.7175 - val_mean_absolute_percentage_error: 22.7175\n",
      "Epoch 100/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5884 - mean_absolute_percentage_error: 23.5884 - val_loss: 22.7221 - val_mean_absolute_percentage_error: 22.7221\n",
      "Epoch 101/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5793 - mean_absolute_percentage_error: 23.5793 - val_loss: 22.7207 - val_mean_absolute_percentage_error: 22.7207\n",
      "Epoch 102/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5835 - mean_absolute_percentage_error: 23.5835 - val_loss: 22.7175 - val_mean_absolute_percentage_error: 22.7175\n",
      "Epoch 103/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5853 - mean_absolute_percentage_error: 23.5853 - val_loss: 22.7210 - val_mean_absolute_percentage_error: 22.7210\n",
      "Epoch 104/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5831 - mean_absolute_percentage_error: 23.5831 - val_loss: 22.7177 - val_mean_absolute_percentage_error: 22.7177\n",
      "Epoch 105/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5836 - mean_absolute_percentage_error: 23.5836 - val_loss: 22.7247 - val_mean_absolute_percentage_error: 22.7247\n",
      "Epoch 106/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5849 - mean_absolute_percentage_error: 23.5849 - val_loss: 22.7184 - val_mean_absolute_percentage_error: 22.7184\n",
      "Epoch 107/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5853 - mean_absolute_percentage_error: 23.5853 - val_loss: 22.7175 - val_mean_absolute_percentage_error: 22.7175\n",
      "Epoch 108/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5827 - mean_absolute_percentage_error: 23.5827 - val_loss: 22.7190 - val_mean_absolute_percentage_error: 22.7190\n",
      "Epoch 109/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5843 - mean_absolute_percentage_error: 23.5843 - val_loss: 22.7196 - val_mean_absolute_percentage_error: 22.7196\n",
      "Epoch 110/250\n",
      "4103/4103 [==============================] - 14s 4ms/step - loss: 23.5822 - mean_absolute_percentage_error: 23.5822 - val_loss: 22.7171 - val_mean_absolute_percentage_error: 22.7171\n",
      "Epoch 111/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5822 - mean_absolute_percentage_error: 23.5822 - val_loss: 22.7185 - val_mean_absolute_percentage_error: 22.7185\n",
      "Epoch 112/250\n",
      "4103/4103 [==============================] - 16s 4ms/step - loss: 23.5834 - mean_absolute_percentage_error: 23.5834 - val_loss: 22.7182 - val_mean_absolute_percentage_error: 22.7182\n",
      "Epoch 113/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5799 - mean_absolute_percentage_error: 23.5799 - val_loss: 22.7226 - val_mean_absolute_percentage_error: 22.7226\n",
      "Epoch 114/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5814 - mean_absolute_percentage_error: 23.5814 - val_loss: 22.7163 - val_mean_absolute_percentage_error: 22.7163\n",
      "Epoch 115/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5842 - mean_absolute_percentage_error: 23.5842 - val_loss: 22.7187 - val_mean_absolute_percentage_error: 22.7187\n",
      "Epoch 116/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5822 - mean_absolute_percentage_error: 23.5822 - val_loss: 22.7185 - val_mean_absolute_percentage_error: 22.7185\n",
      "Epoch 117/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5817 - mean_absolute_percentage_error: 23.5817 - val_loss: 22.7162 - val_mean_absolute_percentage_error: 22.7162\n",
      "Epoch 118/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5833 - mean_absolute_percentage_error: 23.5833 - val_loss: 22.7253 - val_mean_absolute_percentage_error: 22.7253\n",
      "Epoch 119/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5810 - mean_absolute_percentage_error: 23.5810 - val_loss: 22.7232 - val_mean_absolute_percentage_error: 22.7232\n",
      "Epoch 120/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5824 - mean_absolute_percentage_error: 23.5824 - val_loss: 22.7185 - val_mean_absolute_percentage_error: 22.7185\n",
      "Epoch 121/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5823 - mean_absolute_percentage_error: 23.5823 - val_loss: 22.7196 - val_mean_absolute_percentage_error: 22.7196\n",
      "Epoch 122/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5776 - mean_absolute_percentage_error: 23.5776 - val_loss: 22.7153 - val_mean_absolute_percentage_error: 22.7153\n",
      "Epoch 123/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5804 - mean_absolute_percentage_error: 23.5804 - val_loss: 22.7150 - val_mean_absolute_percentage_error: 22.7150\n",
      "Epoch 124/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5804 - mean_absolute_percentage_error: 23.5804 - val_loss: 22.7239 - val_mean_absolute_percentage_error: 22.7239\n",
      "Epoch 125/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5823 - mean_absolute_percentage_error: 23.5823 - val_loss: 22.7225 - val_mean_absolute_percentage_error: 22.7225\n",
      "Epoch 126/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5804 - mean_absolute_percentage_error: 23.5804 - val_loss: 22.7197 - val_mean_absolute_percentage_error: 22.7197\n",
      "Epoch 127/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5767 - mean_absolute_percentage_error: 23.5767 - val_loss: 22.7168 - val_mean_absolute_percentage_error: 22.7168\n",
      "Epoch 128/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5830 - mean_absolute_percentage_error: 23.5830 - val_loss: 22.7171 - val_mean_absolute_percentage_error: 22.7171\n",
      "Epoch 129/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5831 - mean_absolute_percentage_error: 23.5831 - val_loss: 22.7165 - val_mean_absolute_percentage_error: 22.7165\n",
      "Epoch 130/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5774 - mean_absolute_percentage_error: 23.5774 - val_loss: 22.7197 - val_mean_absolute_percentage_error: 22.7197\n",
      "Epoch 131/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5804 - mean_absolute_percentage_error: 23.5804 - val_loss: 22.7213 - val_mean_absolute_percentage_error: 22.7213\n",
      "Epoch 132/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5785 - mean_absolute_percentage_error: 23.5785 - val_loss: 22.7126 - val_mean_absolute_percentage_error: 22.7126\n",
      "Epoch 133/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5804 - mean_absolute_percentage_error: 23.5804 - val_loss: 22.7133 - val_mean_absolute_percentage_error: 22.7133\n",
      "Epoch 134/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5785 - mean_absolute_percentage_error: 23.5785 - val_loss: 22.7158 - val_mean_absolute_percentage_error: 22.7158\n",
      "Epoch 135/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5808 - mean_absolute_percentage_error: 23.5808 - val_loss: 22.7148 - val_mean_absolute_percentage_error: 22.7148\n",
      "Epoch 136/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5826 - mean_absolute_percentage_error: 23.5826 - val_loss: 22.7144 - val_mean_absolute_percentage_error: 22.7144\n",
      "Epoch 137/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5765 - mean_absolute_percentage_error: 23.5765 - val_loss: 22.7128 - val_mean_absolute_percentage_error: 22.7128\n",
      "Epoch 138/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5814 - mean_absolute_percentage_error: 23.5814 - val_loss: 22.7142 - val_mean_absolute_percentage_error: 22.7142\n",
      "Epoch 139/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5827 - mean_absolute_percentage_error: 23.5827 - val_loss: 22.7137 - val_mean_absolute_percentage_error: 22.7137\n",
      "Epoch 140/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5780 - mean_absolute_percentage_error: 23.5780 - val_loss: 22.7187 - val_mean_absolute_percentage_error: 22.7187\n",
      "Epoch 141/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5816 - mean_absolute_percentage_error: 23.5816 - val_loss: 22.7149 - val_mean_absolute_percentage_error: 22.7149\n",
      "Epoch 142/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5809 - mean_absolute_percentage_error: 23.5809 - val_loss: 22.7218 - val_mean_absolute_percentage_error: 22.7218\n",
      "Epoch 143/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5765 - mean_absolute_percentage_error: 23.5765 - val_loss: 22.7152 - val_mean_absolute_percentage_error: 22.7152\n",
      "Epoch 144/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5785 - mean_absolute_percentage_error: 23.5785 - val_loss: 22.7121 - val_mean_absolute_percentage_error: 22.7121\n",
      "Epoch 145/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5810 - mean_absolute_percentage_error: 23.5810 - val_loss: 22.7136 - val_mean_absolute_percentage_error: 22.7136\n",
      "Epoch 146/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5807 - mean_absolute_percentage_error: 23.5807 - val_loss: 22.7163 - val_mean_absolute_percentage_error: 22.7163\n",
      "Epoch 147/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5800 - mean_absolute_percentage_error: 23.5800 - val_loss: 22.7150 - val_mean_absolute_percentage_error: 22.7150\n",
      "Epoch 148/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5834 - mean_absolute_percentage_error: 23.5834 - val_loss: 22.7129 - val_mean_absolute_percentage_error: 22.7129\n",
      "Epoch 149/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5785 - mean_absolute_percentage_error: 23.5785 - val_loss: 22.7142 - val_mean_absolute_percentage_error: 22.7142\n",
      "Epoch 150/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5800 - mean_absolute_percentage_error: 23.5800 - val_loss: 22.7139 - val_mean_absolute_percentage_error: 22.7139\n",
      "Epoch 151/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5770 - mean_absolute_percentage_error: 23.5770 - val_loss: 22.7115 - val_mean_absolute_percentage_error: 22.7115\n",
      "Epoch 152/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5782 - mean_absolute_percentage_error: 23.5782 - val_loss: 22.7119 - val_mean_absolute_percentage_error: 22.7119\n",
      "Epoch 153/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5788 - mean_absolute_percentage_error: 23.5788 - val_loss: 22.7125 - val_mean_absolute_percentage_error: 22.7125\n",
      "Epoch 154/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5787 - mean_absolute_percentage_error: 23.5787 - val_loss: 22.7139 - val_mean_absolute_percentage_error: 22.7139\n",
      "Epoch 155/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5780 - mean_absolute_percentage_error: 23.5780 - val_loss: 22.7147 - val_mean_absolute_percentage_error: 22.7147\n",
      "Epoch 156/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5774 - mean_absolute_percentage_error: 23.5774 - val_loss: 22.7127 - val_mean_absolute_percentage_error: 22.7127\n",
      "Epoch 157/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5833 - mean_absolute_percentage_error: 23.5833 - val_loss: 22.7131 - val_mean_absolute_percentage_error: 22.7131\n",
      "Epoch 158/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5780 - mean_absolute_percentage_error: 23.5780 - val_loss: 22.7132 - val_mean_absolute_percentage_error: 22.7132\n",
      "Epoch 159/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5764 - mean_absolute_percentage_error: 23.5764 - val_loss: 22.7136 - val_mean_absolute_percentage_error: 22.7136\n",
      "Epoch 160/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5794 - mean_absolute_percentage_error: 23.5794 - val_loss: 22.7170 - val_mean_absolute_percentage_error: 22.7170\n",
      "Epoch 161/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5733 - mean_absolute_percentage_error: 23.5733 - val_loss: 22.7128 - val_mean_absolute_percentage_error: 22.7128\n",
      "Epoch 162/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5766 - mean_absolute_percentage_error: 23.5766 - val_loss: 22.7140 - val_mean_absolute_percentage_error: 22.7140\n",
      "Epoch 163/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5799 - mean_absolute_percentage_error: 23.5799 - val_loss: 22.7131 - val_mean_absolute_percentage_error: 22.7131\n",
      "Epoch 164/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5779 - mean_absolute_percentage_error: 23.5779 - val_loss: 22.7153 - val_mean_absolute_percentage_error: 22.7153\n",
      "Epoch 165/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5766 - mean_absolute_percentage_error: 23.5766 - val_loss: 22.7115 - val_mean_absolute_percentage_error: 22.7115\n",
      "Epoch 166/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5792 - mean_absolute_percentage_error: 23.5792 - val_loss: 22.7122 - val_mean_absolute_percentage_error: 22.7122\n",
      "Epoch 167/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5782 - mean_absolute_percentage_error: 23.5782 - val_loss: 22.7168 - val_mean_absolute_percentage_error: 22.7168\n",
      "Epoch 168/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5761 - mean_absolute_percentage_error: 23.5761 - val_loss: 22.7123 - val_mean_absolute_percentage_error: 22.7123\n",
      "Epoch 169/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5753 - mean_absolute_percentage_error: 23.5753 - val_loss: 22.7105 - val_mean_absolute_percentage_error: 22.7105\n",
      "Epoch 170/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5779 - mean_absolute_percentage_error: 23.5779 - val_loss: 22.7132 - val_mean_absolute_percentage_error: 22.7132\n",
      "Epoch 171/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5779 - mean_absolute_percentage_error: 23.5779 - val_loss: 22.7113 - val_mean_absolute_percentage_error: 22.7113\n",
      "Epoch 172/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5779 - mean_absolute_percentage_error: 23.5779 - val_loss: 22.7099 - val_mean_absolute_percentage_error: 22.7099\n",
      "Epoch 173/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5767 - mean_absolute_percentage_error: 23.5767 - val_loss: 22.7107 - val_mean_absolute_percentage_error: 22.7107\n",
      "Epoch 174/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5783 - mean_absolute_percentage_error: 23.5783 - val_loss: 22.7161 - val_mean_absolute_percentage_error: 22.7161\n",
      "Epoch 175/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5749 - mean_absolute_percentage_error: 23.5749 - val_loss: 22.7107 - val_mean_absolute_percentage_error: 22.7107\n",
      "Epoch 176/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5744 - mean_absolute_percentage_error: 23.5744 - val_loss: 22.7118 - val_mean_absolute_percentage_error: 22.7118\n",
      "Epoch 177/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5763 - mean_absolute_percentage_error: 23.5763 - val_loss: 22.7113 - val_mean_absolute_percentage_error: 22.7113\n",
      "Epoch 178/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5744 - mean_absolute_percentage_error: 23.5744 - val_loss: 22.7114 - val_mean_absolute_percentage_error: 22.7114\n",
      "Epoch 179/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5760 - mean_absolute_percentage_error: 23.5760 - val_loss: 22.7102 - val_mean_absolute_percentage_error: 22.7102\n",
      "Epoch 180/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5759 - mean_absolute_percentage_error: 23.5759 - val_loss: 22.7106 - val_mean_absolute_percentage_error: 22.7106\n",
      "Epoch 181/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5744 - mean_absolute_percentage_error: 23.5744 - val_loss: 22.7121 - val_mean_absolute_percentage_error: 22.7121\n",
      "Epoch 182/250\n",
      "4103/4103 [==============================] - 14s 4ms/step - loss: 23.5740 - mean_absolute_percentage_error: 23.5740 - val_loss: 22.7101 - val_mean_absolute_percentage_error: 22.7101\n",
      "Epoch 183/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5790 - mean_absolute_percentage_error: 23.5790 - val_loss: 22.7141 - val_mean_absolute_percentage_error: 22.7141\n",
      "Epoch 184/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5782 - mean_absolute_percentage_error: 23.5782 - val_loss: 22.7159 - val_mean_absolute_percentage_error: 22.7159\n",
      "Epoch 185/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5719 - mean_absolute_percentage_error: 23.5719 - val_loss: 22.7090 - val_mean_absolute_percentage_error: 22.7090\n",
      "Epoch 186/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5774 - mean_absolute_percentage_error: 23.5774 - val_loss: 22.7105 - val_mean_absolute_percentage_error: 22.7105\n",
      "Epoch 187/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5748 - mean_absolute_percentage_error: 23.5748 - val_loss: 22.7126 - val_mean_absolute_percentage_error: 22.7126\n",
      "Epoch 188/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5776 - mean_absolute_percentage_error: 23.5776 - val_loss: 22.7161 - val_mean_absolute_percentage_error: 22.7161\n",
      "Epoch 189/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5742 - mean_absolute_percentage_error: 23.5742 - val_loss: 22.7088 - val_mean_absolute_percentage_error: 22.7088\n",
      "Epoch 190/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5758 - mean_absolute_percentage_error: 23.5758 - val_loss: 22.7092 - val_mean_absolute_percentage_error: 22.7092\n",
      "Epoch 191/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5735 - mean_absolute_percentage_error: 23.5735 - val_loss: 22.7095 - val_mean_absolute_percentage_error: 22.7095\n",
      "Epoch 192/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5763 - mean_absolute_percentage_error: 23.5763 - val_loss: 22.7109 - val_mean_absolute_percentage_error: 22.7109\n",
      "Epoch 193/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5735 - mean_absolute_percentage_error: 23.5735 - val_loss: 22.7092 - val_mean_absolute_percentage_error: 22.7092\n",
      "Epoch 194/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5771 - mean_absolute_percentage_error: 23.5771 - val_loss: 22.7093 - val_mean_absolute_percentage_error: 22.7093\n",
      "Epoch 195/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5767 - mean_absolute_percentage_error: 23.5767 - val_loss: 22.7094 - val_mean_absolute_percentage_error: 22.7094\n",
      "Epoch 196/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5761 - mean_absolute_percentage_error: 23.5761 - val_loss: 22.7117 - val_mean_absolute_percentage_error: 22.7117\n",
      "Epoch 197/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5739 - mean_absolute_percentage_error: 23.5739 - val_loss: 22.7158 - val_mean_absolute_percentage_error: 22.7158\n",
      "Epoch 198/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5765 - mean_absolute_percentage_error: 23.5765 - val_loss: 22.7125 - val_mean_absolute_percentage_error: 22.7125\n",
      "Epoch 199/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5732 - mean_absolute_percentage_error: 23.5732 - val_loss: 22.7086 - val_mean_absolute_percentage_error: 22.7086\n",
      "Epoch 200/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5744 - mean_absolute_percentage_error: 23.5744 - val_loss: 22.7075 - val_mean_absolute_percentage_error: 22.7075\n",
      "Epoch 201/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5809 - mean_absolute_percentage_error: 23.5809 - val_loss: 22.7082 - val_mean_absolute_percentage_error: 22.7082\n",
      "Epoch 202/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5757 - mean_absolute_percentage_error: 23.5757 - val_loss: 22.7094 - val_mean_absolute_percentage_error: 22.7094\n",
      "Epoch 203/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5728 - mean_absolute_percentage_error: 23.5728 - val_loss: 22.7112 - val_mean_absolute_percentage_error: 22.7112\n",
      "Epoch 204/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5747 - mean_absolute_percentage_error: 23.5747 - val_loss: 22.7082 - val_mean_absolute_percentage_error: 22.7082\n",
      "Epoch 205/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5736 - mean_absolute_percentage_error: 23.5736 - val_loss: 22.7085 - val_mean_absolute_percentage_error: 22.7085\n",
      "Epoch 206/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5770 - mean_absolute_percentage_error: 23.5770 - val_loss: 22.7118 - val_mean_absolute_percentage_error: 22.7118\n",
      "Epoch 207/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5735 - mean_absolute_percentage_error: 23.5735 - val_loss: 22.7099 - val_mean_absolute_percentage_error: 22.7099\n",
      "Epoch 208/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5744 - mean_absolute_percentage_error: 23.5744 - val_loss: 22.7092 - val_mean_absolute_percentage_error: 22.7092\n",
      "Epoch 209/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5740 - mean_absolute_percentage_error: 23.5740 - val_loss: 22.7078 - val_mean_absolute_percentage_error: 22.7078\n",
      "Epoch 210/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5722 - mean_absolute_percentage_error: 23.5722 - val_loss: 22.7220 - val_mean_absolute_percentage_error: 22.7220\n",
      "Epoch 211/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5764 - mean_absolute_percentage_error: 23.5764 - val_loss: 22.7089 - val_mean_absolute_percentage_error: 22.7089\n",
      "Epoch 212/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5753 - mean_absolute_percentage_error: 23.5753 - val_loss: 22.7077 - val_mean_absolute_percentage_error: 22.7077\n",
      "Epoch 213/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5741 - mean_absolute_percentage_error: 23.5741 - val_loss: 22.7095 - val_mean_absolute_percentage_error: 22.7095\n",
      "Epoch 214/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5757 - mean_absolute_percentage_error: 23.5757 - val_loss: 22.7077 - val_mean_absolute_percentage_error: 22.7077\n",
      "Epoch 215/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5744 - mean_absolute_percentage_error: 23.5744 - val_loss: 22.7087 - val_mean_absolute_percentage_error: 22.7087\n",
      "Epoch 216/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5760 - mean_absolute_percentage_error: 23.5760 - val_loss: 22.7083 - val_mean_absolute_percentage_error: 22.7083\n",
      "Epoch 217/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5742 - mean_absolute_percentage_error: 23.5742 - val_loss: 22.7156 - val_mean_absolute_percentage_error: 22.7156\n",
      "Epoch 218/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5709 - mean_absolute_percentage_error: 23.5709 - val_loss: 22.7258 - val_mean_absolute_percentage_error: 22.7258\n",
      "Epoch 219/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5757 - mean_absolute_percentage_error: 23.5757 - val_loss: 22.7108 - val_mean_absolute_percentage_error: 22.7108\n",
      "Epoch 220/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5703 - mean_absolute_percentage_error: 23.5703 - val_loss: 22.7091 - val_mean_absolute_percentage_error: 22.7091\n",
      "Epoch 221/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5756 - mean_absolute_percentage_error: 23.5756 - val_loss: 22.7086 - val_mean_absolute_percentage_error: 22.7086\n",
      "Epoch 222/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5726 - mean_absolute_percentage_error: 23.5726 - val_loss: 22.7086 - val_mean_absolute_percentage_error: 22.7086\n",
      "Epoch 223/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5725 - mean_absolute_percentage_error: 23.5725 - val_loss: 22.7061 - val_mean_absolute_percentage_error: 22.7061\n",
      "Epoch 224/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5731 - mean_absolute_percentage_error: 23.5731 - val_loss: 22.7123 - val_mean_absolute_percentage_error: 22.7123\n",
      "Epoch 225/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5742 - mean_absolute_percentage_error: 23.5742 - val_loss: 22.7102 - val_mean_absolute_percentage_error: 22.7102\n",
      "Epoch 226/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5730 - mean_absolute_percentage_error: 23.5730 - val_loss: 22.7100 - val_mean_absolute_percentage_error: 22.7100\n",
      "Epoch 227/250\n",
      "4103/4103 [==============================] - 7s 2ms/step - loss: 23.5735 - mean_absolute_percentage_error: 23.5735 - val_loss: 22.7153 - val_mean_absolute_percentage_error: 22.7153\n",
      "Epoch 228/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5709 - mean_absolute_percentage_error: 23.5709 - val_loss: 22.7078 - val_mean_absolute_percentage_error: 22.7078\n",
      "Epoch 229/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5721 - mean_absolute_percentage_error: 23.5721 - val_loss: 22.7074 - val_mean_absolute_percentage_error: 22.7074\n",
      "Epoch 230/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5743 - mean_absolute_percentage_error: 23.5743 - val_loss: 22.7064 - val_mean_absolute_percentage_error: 22.7064\n",
      "Epoch 231/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5726 - mean_absolute_percentage_error: 23.5726 - val_loss: 22.7084 - val_mean_absolute_percentage_error: 22.7084\n",
      "Epoch 232/250\n",
      "4103/4103 [==============================] - 10s 2ms/step - loss: 23.5748 - mean_absolute_percentage_error: 23.5748 - val_loss: 22.7072 - val_mean_absolute_percentage_error: 22.7072\n",
      "Epoch 233/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5717 - mean_absolute_percentage_error: 23.5717 - val_loss: 22.7075 - val_mean_absolute_percentage_error: 22.7075\n",
      "Epoch 234/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5718 - mean_absolute_percentage_error: 23.5718 - val_loss: 22.7189 - val_mean_absolute_percentage_error: 22.7189\n",
      "Epoch 235/250\n",
      "4103/4103 [==============================] - 8s 2ms/step - loss: 23.5738 - mean_absolute_percentage_error: 23.5738 - val_loss: 22.7078 - val_mean_absolute_percentage_error: 22.7078\n",
      "Epoch 236/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5731 - mean_absolute_percentage_error: 23.5731 - val_loss: 22.7157 - val_mean_absolute_percentage_error: 22.7157\n",
      "Epoch 237/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5746 - mean_absolute_percentage_error: 23.5746 - val_loss: 22.7153 - val_mean_absolute_percentage_error: 22.7153\n",
      "Epoch 238/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5723 - mean_absolute_percentage_error: 23.5723 - val_loss: 22.7065 - val_mean_absolute_percentage_error: 22.7065\n",
      "Epoch 239/250\n",
      "4103/4103 [==============================] - 9s 2ms/step - loss: 23.5751 - mean_absolute_percentage_error: 23.5751 - val_loss: 22.7095 - val_mean_absolute_percentage_error: 22.7095\n",
      "Epoch 240/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5723 - mean_absolute_percentage_error: 23.5723 - val_loss: 22.7090 - val_mean_absolute_percentage_error: 22.7090\n",
      "Epoch 241/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5724 - mean_absolute_percentage_error: 23.5724 - val_loss: 22.7065 - val_mean_absolute_percentage_error: 22.7065\n",
      "Epoch 242/250\n",
      "4103/4103 [==============================] - 15s 4ms/step - loss: 23.5702 - mean_absolute_percentage_error: 23.5702 - val_loss: 22.7055 - val_mean_absolute_percentage_error: 22.7055\n",
      "Epoch 243/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5732 - mean_absolute_percentage_error: 23.5732 - val_loss: 22.7059 - val_mean_absolute_percentage_error: 22.7059\n",
      "Epoch 244/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5728 - mean_absolute_percentage_error: 23.5728 - val_loss: 22.7093 - val_mean_absolute_percentage_error: 22.7093\n",
      "Epoch 245/250\n",
      "4103/4103 [==============================] - 11s 3ms/step - loss: 23.5715 - mean_absolute_percentage_error: 23.5715 - val_loss: 22.7071 - val_mean_absolute_percentage_error: 22.7071\n",
      "Epoch 246/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5726 - mean_absolute_percentage_error: 23.5726 - val_loss: 22.7068 - val_mean_absolute_percentage_error: 22.7068\n",
      "Epoch 247/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5729 - mean_absolute_percentage_error: 23.5729 - val_loss: 22.7078 - val_mean_absolute_percentage_error: 22.7078\n",
      "Epoch 248/250\n",
      "4103/4103 [==============================] - 12s 3ms/step - loss: 23.5713 - mean_absolute_percentage_error: 23.5713 - val_loss: 22.7067 - val_mean_absolute_percentage_error: 22.7067\n",
      "Epoch 249/250\n",
      "4103/4103 [==============================] - 13s 3ms/step - loss: 23.5742 - mean_absolute_percentage_error: 23.5742 - val_loss: 22.7077 - val_mean_absolute_percentage_error: 22.7077\n",
      "Epoch 250/250\n",
      "4103/4103 [==============================] - 14s 3ms/step - loss: 23.5740 - mean_absolute_percentage_error: 23.5740 - val_loss: 22.7090 - val_mean_absolute_percentage_error: 22.7090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c8956f7b50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the model\n",
    "simple_nn.fit(X_train, y_train, epochs=250, batch_size = 32, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c89a45fdf0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c89a46d280>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'model loss')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c89a46d4c0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see what information has been logged during the training process\n",
    "plt.plot(simple_nn.history.history['loss'])\n",
    "plt.plot(simple_nn.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['validation', 'train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model object and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates the model\n",
    "def create_model(neurons=1):\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(neurons, input_dim=X_train.shape[1], activation='relu'))\n",
    "    nn_model.add(Dense(neurons, activation='relu'))\n",
    "    nn_model.add(Dense(1))\n",
    "    nn_model.compile(loss='mean_absolute_percentage_error', optimizer='adam')\n",
    "    return nn_model\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0, neurons=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [32, 50]\n",
    "epochs = [100, 150, 250]\n",
    "neurons = [10, 20, 30]\n",
    "params_grid = dict(batch_size=batch_size, epochs=epochs, neurons=neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [32, 50], 'epochs': [100, 150, 250], 'neurons': [10, 20, 30]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing parameter options\n",
    "params_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_search_nn = GridSearchCV(estimator=model, param_grid=params_grid, n_jobs=-1)\n",
    "grid_search_nn = grid_search_nn.fit(X_train_validation, y_train_validation)\n",
    "end_time = datetime.datetime.now()\n",
    "print(f'hypertuning with sklearn grid search for neural networks complete in {round((end_time - start_time).seconds/60, 2)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the best model and final outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameter combination is: {'batch_size': 32, 'epochs': 250, 'neurons': 30} with score: 0.38487397926401345\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameter combination is: {}\".format(grid_search_nn.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17c8fd22a60>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the model with the train+validation set, with the best parameters of the grid search\n",
    "best_model = create_model(30)\n",
    "best_model.fit(X_train_validation, y_train_validation, epochs=250, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAPE of the nn model is 0.23359821134656183\n"
     ]
    }
   ],
   "source": [
    "#calculating final MAPE score\n",
    "X_test = data_preparer.prepare_data(fitting_splits.test_set).drop(['koopPrijs', 'id'],axis=1)\n",
    "y_test = fitting_splits.test_set['koopPrijs']\n",
    "y_hat_test_nn = best_model.predict(X_test)\n",
    "print(\"The MAPE of the nn model is {}\".format(metrics.mean_absolute_percentage_error(y_test, y_hat_test_nn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment was to develop a machine learning model to predict both sales price and time to sell for housing data from Funda. In this project, two models are used to predict these outcomes: the random forest and neural network model. For both models, the best hyperparameters were searched and applied to determine the final accuracy measure of those models. As an accuracy measure the mean absolute percentage error (MAPE) has been used because it gives a clear number of how accurate it is.\n",
    "\n",
    "The random forest gave a final MAPE of 24.93% and the neural network model a MAPE of 23.36%. It can therefore be concluded that the neural network model is the best model to predict the house price. The difference, however, is very small (<1%>).\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b1827d4b6462cc460901af0bc0d075c933010817877a813d51f78a107cbf6e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
